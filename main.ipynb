{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f61ebfb",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf2fae4",
   "metadata": {},
   "source": [
    "### Scriptiebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a4fad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from src.scrape import ScriptiebankScraper, BiblioScraper\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b68d55ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing data found. Starting fresh.\n",
      "--- Starting scraper for: scriptiebank ---\n",
      "Step 1: Finding all item URLs...\n",
      "Requesting page list: https://scriptiebank.be/?page=0\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=1\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=2\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=3\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=4\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=5\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=6\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=7\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=8\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=9\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=10\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=11\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=12\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=13\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=14\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=15\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=16\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=17\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=18\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=19\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=20\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=21\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=22\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=23\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=24\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=25\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=26\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=27\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=28\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=29\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=30\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=31\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=32\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=33\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=34\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=35\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=36\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=37\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=38\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=39\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=40\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=41\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=42\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=43\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=44\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=45\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=46\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=47\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=48\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=49\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=50\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=51\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=52\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=53\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=54\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=55\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=56\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=57\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=58\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=59\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=60\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=61\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=62\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=63\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=64\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=65\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=66\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=67\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=68\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=69\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=70\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=71\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=72\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=73\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=74\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=75\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=76\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=77\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=78\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=79\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=80\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=81\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=82\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=83\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=84\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=85\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=86\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=87\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=88\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=89\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=90\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=91\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=92\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=93\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=94\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=95\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=96\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=97\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=98\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=99\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=100\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=101\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=102\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=103\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=104\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=105\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=106\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=107\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=108\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=109\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=110\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=111\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=112\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=113\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=114\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=115\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=116\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=117\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=118\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=119\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=120\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=121\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=122\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=123\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=124\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=125\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=126\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=127\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=128\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=129\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=130\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=131\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=132\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=133\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=134\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=135\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=136\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=137\n",
      "  -> Discovered 30 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=138\n",
      "  -> Discovered 28 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=139\n",
      "  -> Discovered 13 new unique URLs on this page.\n",
      "Requesting page list: https://scriptiebank.be/?page=140\n",
      "  -> No URLs found on page. Patience: 1/4\n",
      "Requesting page list: https://scriptiebank.be/?page=141\n",
      "  -> No URLs found on page. Patience: 2/4\n",
      "Requesting page list: https://scriptiebank.be/?page=142\n",
      "  -> No URLs found on page. Patience: 3/4\n",
      "Requesting page list: https://scriptiebank.be/?page=143\n",
      "  -> No URLs found on page. Patience: 4/4\n",
      "\n",
      "Discovered 4181 total unique URLs from source.\n",
      "  -> Added 4181 new items to the dataframe.\n",
      "  -> State saved to data/metadata.csv\n",
      "Turning on gather_metadata since new urls have been found.\n",
      "\n",
      "Step 2: Scraping metadata for items missing it...\n",
      "  -> Found 4181 items to scrape for metadata.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:   2%|▏         | 100/4181 [05:43<4:30:35,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n",
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:   5%|▍         | 200/4181 [11:50<3:54:14,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n",
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:   7%|▋         | 300/4181 [17:35<4:04:10,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n",
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  10%|▉         | 400/4181 [23:30<4:00:11,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n",
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  12%|█▏        | 500/4181 [29:20<3:14:31,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n",
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  14%|█▍        | 600/4181 [35:14<3:06:13,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n",
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  17%|█▋        | 700/4181 [41:05<3:34:58,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n",
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  19%|█▉        | 799/4181 [46:56<3:31:48,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  19%|█▉        | 800/4181 [47:01<3:56:20,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  22%|██▏       | 899/4181 [52:51<3:07:49,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  22%|██▏       | 900/4181 [52:53<2:52:43,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  24%|██▍       | 999/4181 [58:50<3:01:14,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  24%|██▍       | 1000/4181 [58:53<2:54:45,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  26%|██▋       | 1099/4181 [1:04:28<3:00:48,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  26%|██▋       | 1100/4181 [1:04:33<3:10:33,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  29%|██▊       | 1199/4181 [1:10:34<3:17:15,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  29%|██▊       | 1200/4181 [1:10:38<3:20:14,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  31%|███       | 1299/4181 [1:16:22<2:36:48,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  31%|███       | 1300/4181 [1:16:25<2:36:45,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  33%|███▎      | 1399/4181 [1:21:53<2:49:48,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  33%|███▎      | 1400/4181 [1:21:58<3:11:17,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  36%|███▌      | 1499/4181 [1:28:15<3:07:53,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  36%|███▌      | 1500/4181 [1:28:18<2:57:09,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  38%|███▊      | 1599/4181 [1:34:07<2:54:00,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  38%|███▊      | 1600/4181 [1:34:10<2:44:56,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  41%|████      | 1699/4181 [1:39:59<2:34:34,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  41%|████      | 1700/4181 [1:40:02<2:20:07,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  43%|████▎     | 1799/4181 [1:45:43<2:16:45,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  43%|████▎     | 1800/4181 [1:45:48<2:35:00,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  45%|████▌     | 1899/4181 [1:51:34<1:56:16,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  45%|████▌     | 1900/4181 [1:51:37<1:55:18,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  48%|████▊     | 1999/4181 [1:57:34<2:24:53,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  48%|████▊     | 2000/4181 [1:57:38<2:35:09,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  50%|█████     | 2099/4181 [2:03:31<2:07:09,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  50%|█████     | 2100/4181 [2:03:34<1:56:34,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  53%|█████▎    | 2199/4181 [2:09:11<1:40:21,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  53%|█████▎    | 2200/4181 [2:09:17<2:05:07,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  55%|█████▍    | 2299/4181 [2:15:07<1:53:30,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  55%|█████▌    | 2300/4181 [2:15:12<2:04:13,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  57%|█████▋    | 2399/4181 [2:20:42<1:32:45,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  57%|█████▋    | 2400/4181 [2:20:46<1:44:16,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  60%|█████▉    | 2499/4181 [2:26:33<2:33:07,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  60%|█████▉    | 2500/4181 [2:26:38<2:26:21,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  62%|██████▏   | 2599/4181 [2:32:13<1:38:41,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  62%|██████▏   | 2600/4181 [2:32:18<1:48:11,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  65%|██████▍   | 2699/4181 [2:38:00<1:28:31,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  65%|██████▍   | 2700/4181 [2:38:04<1:33:49,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  67%|██████▋   | 2799/4181 [2:43:44<1:16:36,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  67%|██████▋   | 2800/4181 [2:43:47<1:17:15,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  69%|██████▉   | 2899/4181 [2:49:42<1:23:09,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  69%|██████▉   | 2900/4181 [2:49:47<1:28:42,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  72%|███████▏  | 2999/4181 [2:55:32<1:14:23,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  72%|███████▏  | 3000/4181 [2:55:37<1:22:52,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  74%|███████▍  | 3099/4181 [3:01:17<59:20,  3.29s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  74%|███████▍  | 3100/4181 [3:01:20<1:01:35,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  77%|███████▋  | 3199/4181 [3:07:17<1:06:26,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  77%|███████▋  | 3200/4181 [3:07:22<1:09:01,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  79%|███████▉  | 3299/4181 [3:13:05<50:18,  3.42s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  79%|███████▉  | 3300/4181 [3:13:08<48:25,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  81%|████████▏ | 3399/4181 [3:20:41<55:01,  4.22s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  81%|████████▏ | 3400/4181 [3:20:45<54:03,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  84%|████████▎ | 3499/4181 [3:26:52<46:24,  4.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  84%|████████▎ | 3500/4181 [3:26:57<49:21,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  86%|████████▌ | 3599/4181 [3:32:48<36:24,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  86%|████████▌ | 3600/4181 [3:32:54<42:58,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  88%|████████▊ | 3699/4181 [3:38:49<32:26,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  88%|████████▊ | 3700/4181 [3:38:54<34:08,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  91%|█████████ | 3799/4181 [3:44:29<19:56,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  91%|█████████ | 3800/4181 [3:44:34<23:28,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  93%|█████████▎| 3899/4181 [3:50:09<16:54,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  93%|█████████▎| 3900/4181 [3:50:13<16:34,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  96%|█████████▌| 3999/4181 [3:56:54<13:33,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  96%|█████████▌| 4000/4181 [3:57:00<14:42,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  98%|█████████▊| 4099/4181 [4:03:52<03:58,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 100 metadata entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata:  98%|█████████▊| 4100/4181 [4:03:55<04:19,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Progress saved to data/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Metadata: 100%|██████████| 4181/4181 [4:08:35<00:00,  3.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving batch of 81 metadata entries...\n",
      "  -> Progress saved to data/metadata.csv\n",
      "\n",
      "Step 3: Checking for and downloading missing files...\n",
      "  -> Found 4085 items to download.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:   1%|          | 49/4085 [02:59<4:27:07,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:   2%|▏         | 99/4085 [06:58<3:57:58,  3.58s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:   4%|▎         | 149/4085 [10:30<4:01:13,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:   5%|▍         | 199/4085 [13:50<3:50:24,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:   6%|▌         | 249/4085 [17:31<4:22:58,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:   7%|▋         | 299/4085 [21:03<4:42:17,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:   9%|▊         | 349/4085 [24:43<4:13:51,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  10%|▉         | 399/4085 [28:04<3:55:49,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  11%|█         | 449/4085 [31:17<4:22:55,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  12%|█▏        | 499/4085 [34:54<5:05:16,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  13%|█▎        | 549/4085 [38:28<4:22:43,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  15%|█▍        | 599/4085 [42:17<3:07:56,  3.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  16%|█▌        | 649/4085 [45:51<4:48:28,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  17%|█▋        | 685/4085 [48:23<4:37:43,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error: 404 for URL https://scriptiebank.be/file/40856/download?token=Lzkut-1U. Full error: 404 Client Error: Not Found for url: https://scriptiebank.be/file/40856/download?token=Lzkut-1U\n",
      "  -> Download failed (bad response) for https://scriptiebank.be/file/40856/download?token=Lzkut-1U\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  17%|█▋        | 699/4085 [49:17<3:41:42,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  18%|█▊        | 742/4085 [51:58<3:02:45,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error: 404 for URL https://scriptiebank.be/file/2428/download?token=6FNm. Full error: 404 Client Error: Not Found for url: https://scriptiebank.be/file/2428/download?token=6FNm\n",
      "  -> Download failed (bad response) for https://scriptiebank.be/file/2428/download?token=6FNm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  18%|█▊        | 749/4085 [52:22<3:32:46,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  20%|█▉        | 799/4085 [55:37<3:26:52,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  21%|██        | 849/4085 [59:22<4:08:47,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  22%|██▏       | 899/4085 [1:03:02<4:19:57,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  23%|██▎       | 949/4085 [1:06:38<5:19:19,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  24%|██▍       | 999/4085 [1:10:34<6:31:12,  7.61s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  26%|██▌       | 1049/4085 [1:14:34<3:15:24,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  27%|██▋       | 1099/4085 [1:18:31<3:32:43,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  27%|██▋       | 1118/4085 [1:19:41<3:30:10,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error: 404 for URL https://scriptiebank.be/file/60026/download?token=1zpr-lyU. Full error: 404 Client Error: Not Found for url: https://scriptiebank.be/file/60026/download?token=1zpr-lyU\n",
      "  -> Download failed (bad response) for https://scriptiebank.be/file/60026/download?token=1zpr-lyU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  28%|██▊       | 1149/4085 [1:22:43<6:58:45,  8.56s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  29%|██▉       | 1179/4085 [1:25:05<3:38:54,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error: 404 for URL https://scriptiebank.be/file/40982/download?token=809205eX. Full error: 404 Client Error: Not Found for url: https://scriptiebank.be/file/40982/download?token=809205eX\n",
      "  -> Download failed (bad response) for https://scriptiebank.be/file/40982/download?token=809205eX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  29%|██▉       | 1199/4085 [1:26:18<3:09:46,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  31%|███       | 1249/4085 [1:29:38<2:58:22,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  32%|███▏      | 1299/4085 [1:33:04<2:55:25,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  33%|███▎      | 1349/4085 [1:36:27<2:55:43,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  34%|███▍      | 1399/4085 [1:40:06<2:54:49,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  35%|███▌      | 1449/4085 [1:43:30<2:39:07,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  37%|███▋      | 1499/4085 [1:47:07<2:36:24,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  38%|███▊      | 1549/4085 [1:50:58<2:33:23,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  39%|███▉      | 1599/4085 [1:54:06<2:39:25,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  40%|████      | 1649/4085 [1:57:55<2:07:59,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  42%|████▏     | 1699/4085 [2:00:44<2:21:23,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  43%|████▎     | 1749/4085 [2:04:27<2:31:32,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  44%|████▍     | 1799/4085 [2:07:43<3:03:05,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  45%|████▌     | 1849/4085 [2:11:31<4:31:47,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  46%|████▋     | 1899/4085 [2:15:28<2:51:56,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  48%|████▊     | 1949/4085 [2:19:24<2:32:20,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  49%|████▉     | 1999/4085 [2:22:41<2:04:32,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  50%|█████     | 2049/4085 [2:27:03<2:27:23,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  51%|█████▏    | 2099/4085 [2:30:23<1:47:45,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  53%|█████▎    | 2149/4085 [2:33:45<2:03:43,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  54%|█████▍    | 2199/4085 [2:37:27<2:15:00,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  55%|█████▌    | 2249/4085 [2:40:34<2:00:14,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  56%|█████▋    | 2299/4085 [2:44:02<4:02:30,  8.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  58%|█████▊    | 2349/4085 [2:47:35<1:40:33,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  59%|█████▊    | 2399/4085 [2:51:09<2:01:53,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  60%|█████▉    | 2449/4085 [2:54:39<1:48:07,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  61%|██████    | 2499/4085 [2:57:41<1:50:20,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  62%|██████▏   | 2549/4085 [3:01:03<2:01:38,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  64%|██████▎   | 2599/4085 [3:04:25<1:38:50,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  65%|██████▍   | 2649/4085 [3:07:58<1:53:17,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  66%|██████▌   | 2699/4085 [3:11:16<1:29:20,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  67%|██████▋   | 2749/4085 [3:14:44<1:58:28,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  69%|██████▊   | 2799/4085 [3:18:41<1:18:26,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  70%|██████▉   | 2849/4085 [3:22:22<1:21:07,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  71%|███████   | 2899/4085 [3:26:00<1:32:18,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  72%|███████▏  | 2949/4085 [3:29:48<1:17:51,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  73%|███████▎  | 2999/4085 [3:33:02<1:07:24,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  75%|███████▍  | 3049/4085 [3:36:13<1:02:16,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  76%|███████▌  | 3099/4085 [3:40:21<1:15:41,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  77%|███████▋  | 3149/4085 [3:44:40<57:58,  3.72s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  78%|███████▊  | 3199/4085 [3:47:55<1:01:19,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  80%|███████▉  | 3249/4085 [3:51:29<53:42,  3.86s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  81%|████████  | 3299/4085 [3:55:47<1:26:28,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  82%|████████▏ | 3349/4085 [3:59:39<49:57,  4.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  83%|████████▎ | 3399/4085 [4:03:24<42:04,  3.68s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  84%|████████▍ | 3449/4085 [4:07:31<39:28,  3.72s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  86%|████████▌ | 3499/4085 [4:11:58<40:47,  4.18s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  87%|████████▋ | 3549/4085 [4:15:48<43:08,  4.83s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  88%|████████▊ | 3599/4085 [4:20:06<28:04,  3.47s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  89%|████████▉ | 3649/4085 [4:23:38<31:05,  4.28s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  91%|█████████ | 3699/4085 [4:28:14<28:27,  4.42s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  92%|█████████▏| 3749/4085 [4:31:39<20:54,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  93%|█████████▎| 3799/4085 [4:35:04<16:56,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  94%|█████████▍| 3849/4085 [4:38:39<15:52,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  95%|█████████▌| 3899/4085 [4:43:25<15:11,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  97%|█████████▋| 3949/4085 [4:47:18<11:16,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  98%|█████████▊| 3999/4085 [4:50:49<05:43,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  99%|█████████▉| 4049/4085 [4:54:33<02:10,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving download progress for 50 items to data/metadata.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:  99%|█████████▉| 4060/4085 [4:55:23<01:29,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error: 404 for URL https://scriptiebank.be/file/108581/download?token=waJ5NYqX. Full error: 404 Client Error: Not Found for url: https://scriptiebank.be/file/108581/download?token=waJ5NYqX\n",
      "  -> Download failed (bad response) for https://scriptiebank.be/file/108581/download?token=waJ5NYqX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files: 100%|██████████| 4085/4085 [4:56:58<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving final batch of 35 item to data/metadata.csv\n",
      "  -> Downloaded 4080 new files.\n",
      " -> state updated and saved to data/metadata.csv\n",
      "\n",
      "--- Scraper for scriptiebank finished. ---\n"
     ]
    }
   ],
   "source": [
    "scriptiebank = ScriptiebankScraper()\n",
    "scriptiebank.run(gather_metadata=True,gather_urls=True,download_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11022c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4182"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scriptiebank_meta = pd.read_csv(Path('data/metadata.csv'))\n",
    "len(scriptiebank_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "724eb506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'first_name', 'last_name', 'college', 'year', 'promoter',\n",
       "       'themes', 'keywords', 'text_homepage', 'page_link', 'download_link',\n",
       "       'downloaded', 'source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scriptiebank_meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8b8d411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scriptiebank_meta_download = scriptiebank_meta[scriptiebank_meta['downloaded']==True]\n",
    "len(scriptiebank_meta_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7a7ff7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "downloaded\n",
       "True     429\n",
       "False      5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scriptiebank_meta.downloaded.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "741c367e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>college</th>\n",
       "      <th>year</th>\n",
       "      <th>promoter</th>\n",
       "      <th>themes</th>\n",
       "      <th>keywords</th>\n",
       "      <th>text_homepage</th>\n",
       "      <th>page_link</th>\n",
       "      <th>download_link</th>\n",
       "      <th>downloaded</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>China &amp; India: verleden, heden en toekomst</td>\n",
       "      <td>Tim JJ</td>\n",
       "      <td>Nelissen</td>\n",
       "      <td>Universiteit Antwerpen</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>['Prof. Dr. Jan Melissen']</td>\n",
       "      <td>['Economische en toegepaste economische wetens...</td>\n",
       "      <td>['economie']</td>\n",
       "      <td>['BRIC, BRICS, BASIC, … zijn letterwoorden die...</td>\n",
       "      <td>https://scriptiebank.be/scriptie/2011/tales-dr...</td>\n",
       "      <td>https://scriptiebank.be/file/14819/download?to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>scriptiebank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Wat de tolk u niet vertelt...</td>\n",
       "      <td>Evy</td>\n",
       "      <td>Cox</td>\n",
       "      <td>KU Leuven</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['prof. dr. Heidi Salaets']</td>\n",
       "      <td>['Taal-en Letterkunde']</td>\n",
       "      <td>['weglating, accuraatheid, tolkmodus, cognitiv...</td>\n",
       "      <td>['Twintig procent. Dat is de hoeveelheid infor...</td>\n",
       "      <td>https://scriptiebank.be/scriptie/2017/accuraat...</td>\n",
       "      <td>https://scriptiebank.be/file/10585/download?to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>scriptiebank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Vergaderen: een moordenaar op kousenvoeten</td>\n",
       "      <td>Serge</td>\n",
       "      <td>Ribas</td>\n",
       "      <td>Odisee Hogeschool</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['Annemie Van Hecke']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Vergaderen, vergaderleed, sedentair gedrag, ...</td>\n",
       "      <td>['Iedereen kent ze wel: de vergaderingen die w...</td>\n",
       "      <td>https://scriptiebank.be/scriptie/2017/actuele-...</td>\n",
       "      <td>https://scriptiebank.be/file/10513/download?to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>scriptiebank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Kantelpunten in de adaptatie van populaties in...</td>\n",
       "      <td>Maxime</td>\n",
       "      <td>Fajgenblat</td>\n",
       "      <td>KU Leuven</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['Prof. Dr. Luc De Meester']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Regime shifts', 'Evolutiebiologie', 'Landsch...</td>\n",
       "      <td>['Als gevolg van een opwarmend klimaat, invasi...</td>\n",
       "      <td>https://scriptiebank.be/scriptie/2017/adaptati...</td>\n",
       "      <td>https://scriptiebank.be/file/10736/download?to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>scriptiebank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A.D.E.M. voor de HerstelAcademie!</td>\n",
       "      <td>Herbots</td>\n",
       "      <td>Marleen</td>\n",
       "      <td>Andere</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['Geert De Maertelaere']</td>\n",
       "      <td>['Sociale gezondheidswetenschappen']</td>\n",
       "      <td>['omkaderingsbeleid, ervaringsdeskundige, psyc...</td>\n",
       "      <td>['De geestelijke gezondheidszorg (ggz) heeft d...</td>\n",
       "      <td>https://scriptiebank.be/scriptie/2017/adem-voo...</td>\n",
       "      <td>https://scriptiebank.be/file/10137/download?to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>scriptiebank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>4177</td>\n",
       "      <td>Stille pijn, luide boodschap: pijn herkennen b...</td>\n",
       "      <td>Milena</td>\n",
       "      <td>De Mesmaeker</td>\n",
       "      <td>HOGENT</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>['De Bou Veerle en Philips Paul']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['pijn', 'Dementie', 'sensibilisering', 'zorgv...</td>\n",
       "      <td>['In Vlaamse woonzorgcentra lijdt een groot de...</td>\n",
       "      <td>https://scriptiebank.be/scriptie/2025/welke-se...</td>\n",
       "      <td>https://scriptiebank.be/file/23208/download?to...</td>\n",
       "      <td>True</td>\n",
       "      <td>scriptiebank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4178</th>\n",
       "      <td>4178</td>\n",
       "      <td>Inclusief onderwijs: Wat kinderen met autisme ...</td>\n",
       "      <td>Camille</td>\n",
       "      <td>Martens</td>\n",
       "      <td>Universiteit Gent</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>['Marieke Coussens']</td>\n",
       "      <td>['Bewegings- en revalidatiewetenschappen', 'Ps...</td>\n",
       "      <td>['Autisme', 'Basisschool', 'leerlingenparticip...</td>\n",
       "      <td>['Hoe kunnen kinderen met autisme écht tot hun...</td>\n",
       "      <td>https://scriptiebank.be/scriptie/2025/what-do-...</td>\n",
       "      <td>https://scriptiebank.be/file/21129/download?to...</td>\n",
       "      <td>True</td>\n",
       "      <td>scriptiebank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4179</th>\n",
       "      <td>4179</td>\n",
       "      <td>Winkelen als belevenis: hoe architectuur de mo...</td>\n",
       "      <td>Mira</td>\n",
       "      <td>Nietvelt</td>\n",
       "      <td>Universiteit Gent</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>['Maude Bass-Krueger', 'Karen Van Godtsenhoven...</td>\n",
       "      <td>['Architectuur']</td>\n",
       "      <td>['mode', 'emotie', 'branding', 'Beleving', 're...</td>\n",
       "      <td>['De Prada Epicenter Store in SoHo, New York. ...</td>\n",
       "      <td>https://scriptiebank.be/scriptie/2025/why-arch...</td>\n",
       "      <td>https://scriptiebank.be/file/21241/download?to...</td>\n",
       "      <td>True</td>\n",
       "      <td>scriptiebank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>4180</td>\n",
       "      <td>Een warme knuffel als pijnstiller voor de alle...</td>\n",
       "      <td>Amber</td>\n",
       "      <td>Monten</td>\n",
       "      <td>Thomas More Hogeschool</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>['Nicky Lembrechts']</td>\n",
       "      <td>['Geneeskunde']</td>\n",
       "      <td>['Neonatale Intensieve Zorg', 'Verpleegkunde',...</td>\n",
       "      <td>['Wat als een knuffel krachtiger is dan een pi...</td>\n",
       "      <td>https://scriptiebank.be/scriptie/2025/zachte-w...</td>\n",
       "      <td>https://scriptiebank.be/file/20923/download?to...</td>\n",
       "      <td>True</td>\n",
       "      <td>scriptiebank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4181</th>\n",
       "      <td>4181</td>\n",
       "      <td>\"Ze vertelden me dat het zeker geen gevangenis...</td>\n",
       "      <td>Zoye</td>\n",
       "      <td>Provoost</td>\n",
       "      <td>Vrije Universiteit Brussel</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>['Lukas Sengers', 'Ruben Brugnera']</td>\n",
       "      <td>['Journalistiek']</td>\n",
       "      <td>['Internationale en nationale studenten', 'Det...</td>\n",
       "      <td>['Minstens zes buitenlandse studenten zijn de ...</td>\n",
       "      <td>https://scriptiebank.be/scriptie/2025/ze-verte...</td>\n",
       "      <td>https://scriptiebank.be/file/21950/download?to...</td>\n",
       "      <td>True</td>\n",
       "      <td>scriptiebank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4182 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title first_name  \\\n",
       "0        0         China & India: verleden, heden en toekomst     Tim JJ   \n",
       "1        1                      Wat de tolk u niet vertelt...        Evy   \n",
       "2        2         Vergaderen: een moordenaar op kousenvoeten      Serge   \n",
       "3        3  Kantelpunten in de adaptatie van populaties in...     Maxime   \n",
       "4        4                  A.D.E.M. voor de HerstelAcademie!    Herbots   \n",
       "...    ...                                                ...        ...   \n",
       "4177  4177  Stille pijn, luide boodschap: pijn herkennen b...     Milena   \n",
       "4178  4178  Inclusief onderwijs: Wat kinderen met autisme ...    Camille   \n",
       "4179  4179  Winkelen als belevenis: hoe architectuur de mo...       Mira   \n",
       "4180  4180  Een warme knuffel als pijnstiller voor de alle...      Amber   \n",
       "4181  4181  \"Ze vertelden me dat het zeker geen gevangenis...       Zoye   \n",
       "\n",
       "         last_name                     college    year  \\\n",
       "0         Nelissen      Universiteit Antwerpen  2011.0   \n",
       "1              Cox                   KU Leuven  2017.0   \n",
       "2            Ribas           Odisee Hogeschool  2017.0   \n",
       "3       Fajgenblat                   KU Leuven  2017.0   \n",
       "4          Marleen                      Andere  2017.0   \n",
       "...            ...                         ...     ...   \n",
       "4177  De Mesmaeker                      HOGENT  2025.0   \n",
       "4178       Martens           Universiteit Gent  2025.0   \n",
       "4179      Nietvelt           Universiteit Gent  2025.0   \n",
       "4180        Monten      Thomas More Hogeschool  2025.0   \n",
       "4181      Provoost  Vrije Universiteit Brussel  2025.0   \n",
       "\n",
       "                                               promoter  \\\n",
       "0                            ['Prof. Dr. Jan Melissen']   \n",
       "1                           ['prof. dr. Heidi Salaets']   \n",
       "2                                 ['Annemie Van Hecke']   \n",
       "3                          ['Prof. Dr. Luc De Meester']   \n",
       "4                              ['Geert De Maertelaere']   \n",
       "...                                                 ...   \n",
       "4177                  ['De Bou Veerle en Philips Paul']   \n",
       "4178                               ['Marieke Coussens']   \n",
       "4179  ['Maude Bass-Krueger', 'Karen Van Godtsenhoven...   \n",
       "4180                               ['Nicky Lembrechts']   \n",
       "4181                ['Lukas Sengers', 'Ruben Brugnera']   \n",
       "\n",
       "                                                 themes  \\\n",
       "0     ['Economische en toegepaste economische wetens...   \n",
       "1                               ['Taal-en Letterkunde']   \n",
       "2                                                    []   \n",
       "3                                                    []   \n",
       "4                  ['Sociale gezondheidswetenschappen']   \n",
       "...                                                 ...   \n",
       "4177                                                 []   \n",
       "4178  ['Bewegings- en revalidatiewetenschappen', 'Ps...   \n",
       "4179                                   ['Architectuur']   \n",
       "4180                                    ['Geneeskunde']   \n",
       "4181                                  ['Journalistiek']   \n",
       "\n",
       "                                               keywords  \\\n",
       "0                                          ['economie']   \n",
       "1     ['weglating, accuraatheid, tolkmodus, cognitiv...   \n",
       "2     ['Vergaderen, vergaderleed, sedentair gedrag, ...   \n",
       "3     ['Regime shifts', 'Evolutiebiologie', 'Landsch...   \n",
       "4     ['omkaderingsbeleid, ervaringsdeskundige, psyc...   \n",
       "...                                                 ...   \n",
       "4177  ['pijn', 'Dementie', 'sensibilisering', 'zorgv...   \n",
       "4178  ['Autisme', 'Basisschool', 'leerlingenparticip...   \n",
       "4179  ['mode', 'emotie', 'branding', 'Beleving', 're...   \n",
       "4180  ['Neonatale Intensieve Zorg', 'Verpleegkunde',...   \n",
       "4181  ['Internationale en nationale studenten', 'Det...   \n",
       "\n",
       "                                          text_homepage  \\\n",
       "0     ['BRIC, BRICS, BASIC, … zijn letterwoorden die...   \n",
       "1     ['Twintig procent. Dat is de hoeveelheid infor...   \n",
       "2     ['Iedereen kent ze wel: de vergaderingen die w...   \n",
       "3     ['Als gevolg van een opwarmend klimaat, invasi...   \n",
       "4     ['De geestelijke gezondheidszorg (ggz) heeft d...   \n",
       "...                                                 ...   \n",
       "4177  ['In Vlaamse woonzorgcentra lijdt een groot de...   \n",
       "4178  ['Hoe kunnen kinderen met autisme écht tot hun...   \n",
       "4179  ['De Prada Epicenter Store in SoHo, New York. ...   \n",
       "4180  ['Wat als een knuffel krachtiger is dan een pi...   \n",
       "4181  ['Minstens zes buitenlandse studenten zijn de ...   \n",
       "\n",
       "                                              page_link  \\\n",
       "0     https://scriptiebank.be/scriptie/2011/tales-dr...   \n",
       "1     https://scriptiebank.be/scriptie/2017/accuraat...   \n",
       "2     https://scriptiebank.be/scriptie/2017/actuele-...   \n",
       "3     https://scriptiebank.be/scriptie/2017/adaptati...   \n",
       "4     https://scriptiebank.be/scriptie/2017/adem-voo...   \n",
       "...                                                 ...   \n",
       "4177  https://scriptiebank.be/scriptie/2025/welke-se...   \n",
       "4178  https://scriptiebank.be/scriptie/2025/what-do-...   \n",
       "4179  https://scriptiebank.be/scriptie/2025/why-arch...   \n",
       "4180  https://scriptiebank.be/scriptie/2025/zachte-w...   \n",
       "4181  https://scriptiebank.be/scriptie/2025/ze-verte...   \n",
       "\n",
       "                                          download_link downloaded  \\\n",
       "0     https://scriptiebank.be/file/14819/download?to...        NaN   \n",
       "1     https://scriptiebank.be/file/10585/download?to...        NaN   \n",
       "2     https://scriptiebank.be/file/10513/download?to...        NaN   \n",
       "3     https://scriptiebank.be/file/10736/download?to...        NaN   \n",
       "4     https://scriptiebank.be/file/10137/download?to...        NaN   \n",
       "...                                                 ...        ...   \n",
       "4177  https://scriptiebank.be/file/23208/download?to...       True   \n",
       "4178  https://scriptiebank.be/file/21129/download?to...       True   \n",
       "4179  https://scriptiebank.be/file/21241/download?to...       True   \n",
       "4180  https://scriptiebank.be/file/20923/download?to...       True   \n",
       "4181  https://scriptiebank.be/file/21950/download?to...       True   \n",
       "\n",
       "            source  \n",
       "0     scriptiebank  \n",
       "1     scriptiebank  \n",
       "2     scriptiebank  \n",
       "3     scriptiebank  \n",
       "4     scriptiebank  \n",
       "...            ...  \n",
       "4177  scriptiebank  \n",
       "4178  scriptiebank  \n",
       "4179  scriptiebank  \n",
       "4180  scriptiebank  \n",
       "4181  scriptiebank  \n",
       "\n",
       "[4182 rows x 14 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scriptiebank_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41333f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>college</th>\n",
       "      <th>year</th>\n",
       "      <th>promoter</th>\n",
       "      <th>themes</th>\n",
       "      <th>keywords</th>\n",
       "      <th>text_homepage</th>\n",
       "      <th>page_link</th>\n",
       "      <th>download_link</th>\n",
       "      <th>downloaded</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>China &amp; India: verleden, heden en toekomst</td>\n",
       "      <td>Tim JJ</td>\n",
       "      <td>Nelissen</td>\n",
       "      <td>Universiteit Antwerpen</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>['Prof. Dr. Jan Melissen']</td>\n",
       "      <td>['Economische en toegepaste economische wetens...</td>\n",
       "      <td>['economie']</td>\n",
       "      <td>['BRIC, BRICS, BASIC, … zijn letterwoorden die...</td>\n",
       "      <td>https://scriptiebank.be/scriptie/2011/tales-dr...</td>\n",
       "      <td>https://scriptiebank.be/file/14819/download?to...</td>\n",
       "      <td>True</td>\n",
       "      <td>scriptiebank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Wat de tolk u niet vertelt...</td>\n",
       "      <td>Evy</td>\n",
       "      <td>Cox</td>\n",
       "      <td>KU Leuven</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['prof. dr. Heidi Salaets']</td>\n",
       "      <td>['Taal-en Letterkunde']</td>\n",
       "      <td>['weglating, accuraatheid, tolkmodus, cognitiv...</td>\n",
       "      <td>['Twintig procent. Dat is de hoeveelheid infor...</td>\n",
       "      <td>https://scriptiebank.be/scriptie/2017/accuraat...</td>\n",
       "      <td>https://scriptiebank.be/file/10585/download?to...</td>\n",
       "      <td>True</td>\n",
       "      <td>scriptiebank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Vergaderen: een moordenaar op kousenvoeten</td>\n",
       "      <td>Serge</td>\n",
       "      <td>Ribas</td>\n",
       "      <td>Odisee Hogeschool</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['Annemie Van Hecke']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Vergaderen, vergaderleed, sedentair gedrag, ...</td>\n",
       "      <td>['Iedereen kent ze wel: de vergaderingen die w...</td>\n",
       "      <td>https://scriptiebank.be/scriptie/2017/actuele-...</td>\n",
       "      <td>https://scriptiebank.be/file/10513/download?to...</td>\n",
       "      <td>True</td>\n",
       "      <td>scriptiebank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Kantelpunten in de adaptatie van populaties in...</td>\n",
       "      <td>Maxime</td>\n",
       "      <td>Fajgenblat</td>\n",
       "      <td>KU Leuven</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['Prof. Dr. Luc De Meester']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Regime shifts', 'Evolutiebiologie', 'Landsch...</td>\n",
       "      <td>['Als gevolg van een opwarmend klimaat, invasi...</td>\n",
       "      <td>https://scriptiebank.be/scriptie/2017/adaptati...</td>\n",
       "      <td>https://scriptiebank.be/file/10736/download?to...</td>\n",
       "      <td>True</td>\n",
       "      <td>scriptiebank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A.D.E.M. voor de HerstelAcademie!</td>\n",
       "      <td>Herbots</td>\n",
       "      <td>Marleen</td>\n",
       "      <td>Andere</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['Geert De Maertelaere']</td>\n",
       "      <td>['Sociale gezondheidswetenschappen']</td>\n",
       "      <td>['omkaderingsbeleid, ervaringsdeskundige, psyc...</td>\n",
       "      <td>['De geestelijke gezondheidszorg (ggz) heeft d...</td>\n",
       "      <td>https://scriptiebank.be/scriptie/2017/adem-voo...</td>\n",
       "      <td>https://scriptiebank.be/file/10137/download?to...</td>\n",
       "      <td>True</td>\n",
       "      <td>scriptiebank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title first_name  \\\n",
       "0   0         China & India: verleden, heden en toekomst     Tim JJ   \n",
       "1   1                      Wat de tolk u niet vertelt...        Evy   \n",
       "2   2         Vergaderen: een moordenaar op kousenvoeten      Serge   \n",
       "3   3  Kantelpunten in de adaptatie van populaties in...     Maxime   \n",
       "4   4                  A.D.E.M. voor de HerstelAcademie!    Herbots   \n",
       "\n",
       "    last_name                 college    year                      promoter  \\\n",
       "0    Nelissen  Universiteit Antwerpen  2011.0    ['Prof. Dr. Jan Melissen']   \n",
       "1         Cox               KU Leuven  2017.0   ['prof. dr. Heidi Salaets']   \n",
       "2       Ribas       Odisee Hogeschool  2017.0         ['Annemie Van Hecke']   \n",
       "3  Fajgenblat               KU Leuven  2017.0  ['Prof. Dr. Luc De Meester']   \n",
       "4     Marleen                  Andere  2017.0      ['Geert De Maertelaere']   \n",
       "\n",
       "                                              themes  \\\n",
       "0  ['Economische en toegepaste economische wetens...   \n",
       "1                            ['Taal-en Letterkunde']   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4               ['Sociale gezondheidswetenschappen']   \n",
       "\n",
       "                                            keywords  \\\n",
       "0                                       ['economie']   \n",
       "1  ['weglating, accuraatheid, tolkmodus, cognitiv...   \n",
       "2  ['Vergaderen, vergaderleed, sedentair gedrag, ...   \n",
       "3  ['Regime shifts', 'Evolutiebiologie', 'Landsch...   \n",
       "4  ['omkaderingsbeleid, ervaringsdeskundige, psyc...   \n",
       "\n",
       "                                       text_homepage  \\\n",
       "0  ['BRIC, BRICS, BASIC, … zijn letterwoorden die...   \n",
       "1  ['Twintig procent. Dat is de hoeveelheid infor...   \n",
       "2  ['Iedereen kent ze wel: de vergaderingen die w...   \n",
       "3  ['Als gevolg van een opwarmend klimaat, invasi...   \n",
       "4  ['De geestelijke gezondheidszorg (ggz) heeft d...   \n",
       "\n",
       "                                           page_link  \\\n",
       "0  https://scriptiebank.be/scriptie/2011/tales-dr...   \n",
       "1  https://scriptiebank.be/scriptie/2017/accuraat...   \n",
       "2  https://scriptiebank.be/scriptie/2017/actuele-...   \n",
       "3  https://scriptiebank.be/scriptie/2017/adaptati...   \n",
       "4  https://scriptiebank.be/scriptie/2017/adem-voo...   \n",
       "\n",
       "                                       download_link  downloaded        source  \n",
       "0  https://scriptiebank.be/file/14819/download?to...        True  scriptiebank  \n",
       "1  https://scriptiebank.be/file/10585/download?to...        True  scriptiebank  \n",
       "2  https://scriptiebank.be/file/10513/download?to...        True  scriptiebank  \n",
       "3  https://scriptiebank.be/file/10736/download?to...        True  scriptiebank  \n",
       "4  https://scriptiebank.be/file/10137/download?to...        True  scriptiebank  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(Path('data/metadata.csv'))\n",
    "df.head()\n",
    "\n",
    "import zipfile\n",
    "\n",
    "zip = Path('data/archive.zip')\n",
    "def check_download(df,zip):\n",
    "    with zipfile.ZipFile(zip,'r') as zipf:\n",
    "        downloaded_set = {Path(filename).stem for filename in zipf.namelist()}\n",
    "        df['downloaded'] = df['id'].astype(str).isin(downloaded_set)\n",
    "    return df\n",
    "\n",
    "df_scriptiebank= check_download(df,zip)\n",
    "df_scriptiebank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a768abc7",
   "metadata": {},
   "source": [
    "### Gent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ddf1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOWNLOAD UGENT JSON IF DOESNT EXIST\n",
    "import requests\n",
    "\n",
    "PATH_UGENT_JSON = Path('data/ugent_datadump/publications.json')\n",
    "datadump_url = 'https://biblio.ugent.be/exports/publications.json'\n",
    "\n",
    "if not PATH_UGENT_JSON.exists():\n",
    "    print(f'Downloading ugent datadump from {PATH_UGENT_JSON}')\n",
    "\n",
    "    try:\n",
    "        PATH_UGENT_JSON.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with requests.get(datadump_url, stream=True) as response:\n",
    "            response.raise_for_status()\n",
    "            with open(PATH_UGENT_JSON, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        print(f'Sucessfully downloaded to {PATH_UGENT_JSON}')\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f'error during download {e}')\n",
    "else:\n",
    "    print(f'File already exists at: {PATH_UGENT_JSON}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48002010",
   "metadata": {},
   "source": [
    "inspection uses .summarize() from dataframecleaner in src/mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d9a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.mu import DataFrameCleaner\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "c_ug = DataFrameCleaner(Path('data/ugent_datadump/publications.json'))\n",
    "c_ug.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea6d637",
   "metadata": {},
   "source": [
    "Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b9fa72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting ugent datadump download\n",
      "File already exists at: data/ugent_datadump/publications.json\n",
      "Dataframe cleaner initialized, working on copy\n",
      "Showing all rows, set back with pd.set_option('display.max_rows', 10 idk)\n",
      "--- Auto-Inferring Schema (Sample n=1000) ---\n",
      "  > Detected 'publisher' as DICT\n",
      "  > Detected 'author' as LIST\n",
      "  > Detected 'affiliation' as LIST\n",
      "  > Detected 'related_publication' as LIST\n",
      "  > Detected 'keyword' as LIST\n",
      "  > Detected 'doi' as LIST\n",
      "  > Detected 'external' as BOOL (Binary Numeric)\n",
      "  > Detected 'abstract' as LIST\n",
      "  > Detected 'abstract_full' as LIST\n",
      "  > Detected 'format' as LIST\n",
      "  > Detected 'created_by' as DICT\n",
      "  > Detected 'project' as LIST\n",
      "  > Detected 'language' as LIST\n",
      "  > Detected 'identifier' as LIST\n",
      "  > Detected 'jcr' as DICT\n",
      "  > Detected 'page' as DICT\n",
      "  > Detected 'conference' as DICT\n",
      "  > Detected 'issn' as LIST\n",
      "  > Detected 'cite' as DICT\n",
      "  > Detected 'subject' as LIST\n",
      "  > Detected 'parent' as DICT\n",
      "  > Detected 'source' as DICT\n",
      "  > Detected 'editor' as LIST\n",
      "  > Detected 'isbn' as LIST\n",
      "  > Detected 'vabb_approved' as BOOL (Binary Numeric)\n",
      "  > Detected 'vabb_year' as LIST\n",
      "  > Detected 'file' as LIST\n",
      "  > Detected 'alternative_title' as LIST\n",
      "  > Detected 'defense' as DICT\n",
      "  > Detected 'promoter' as LIST\n",
      "  > Detected 'related_dataset' as LIST\n",
      "  > Detected 'alternative_location' as LIST\n",
      "--- Enforcing Schema on 69 columns ---\n",
      "\n",
      "[Cleaning Report] Values converted to NaN:\n",
      "\n",
      "Column               | Total  | Regex Match | Type Mismatch | Detected Garbage\n",
      "----------------------------------------------------------------------------------------------------\n",
      "issue                | 43     | 43          | 0             | ['?', 'N/A']\n",
      "jcr                  | 249408 | 0           | 249408        | []\n",
      "volume               | 19     | 19          | 0             | ['?', '/', '-', 'N/A']\n",
      "Dropped columns (> 95.0% missing): ['url', 'related_publication', 'access_level', 'license', 'format', 'other_license', 'identifier', 'alternative_title', 'defense', 'promoter', 'issue_title', 'edition', 'esci_id', 'related_dataset', 'arxiv_id', 'embargo', 'embargo_to', 'date_from']\n",
      "Dropped 0 duplicates.\n",
      "Step 0: Checking for mixed types before conversion...\n",
      "Step 1: Auto converting to PyArrow-backed types...\n",
      "publisher                           object\n",
      "author                              object\n",
      "affiliation                         object\n",
      "status                     string[pyarrow]\n",
      "biblio_id                  string[pyarrow]\n",
      "handle                     string[pyarrow]\n",
      "_id                        string[pyarrow]\n",
      "keyword                             object\n",
      "title                      string[pyarrow]\n",
      "doi                                 object\n",
      "type                       string[pyarrow]\n",
      "external                     bool[pyarrow]\n",
      "abstract                            object\n",
      "abstract_full                       object\n",
      "year                        int64[pyarrow]\n",
      "date_created               string[pyarrow]\n",
      "created_by                          object\n",
      "copyright_statement        string[pyarrow]\n",
      "date_updated               string[pyarrow]\n",
      "project                             object\n",
      "language                            object\n",
      "issue                      string[pyarrow]\n",
      "jcr                                 object\n",
      "publication_status         string[pyarrow]\n",
      "classification             string[pyarrow]\n",
      "page                                object\n",
      "conference                          object\n",
      "issn                                object\n",
      "cite                                object\n",
      "subject                             object\n",
      "parent                              object\n",
      "volume                     string[pyarrow]\n",
      "source                              object\n",
      "publication_status_sort     int64[pyarrow]\n",
      "conference_type            string[pyarrow]\n",
      "editor                              object\n",
      "isbn                                object\n",
      "vabb_type                  string[pyarrow]\n",
      "vabb_id                    string[pyarrow]\n",
      "vabb_approved                bool[pyarrow]\n",
      "article_type               string[pyarrow]\n",
      "vabb_year                           object\n",
      "file                                object\n",
      "wos_type                   string[pyarrow]\n",
      "wos_id                     string[pyarrow]\n",
      "article_number             string[pyarrow]\n",
      "additional_info            string[pyarrow]\n",
      "misc_type                  string[pyarrow]\n",
      "pubmed_id                  string[pyarrow]\n",
      "series_title               string[pyarrow]\n",
      "alternative_location                object\n",
      "dtype: object\n",
      "Step 2: converting object types\n",
      " > publisher: struct<location: string, name: string>\n",
      " > author: list<item: struct<_id: string, affiliation: list<item: struct<name: string, path: list<item: struct<ugent_id: string>>, ugent_id: string>>, biblio_id: string, credit_role: list<item: string>, first_name: string, last_name: string, name: string, name_last_first: string, orcid_id: string, ugent_id: list<item: string>>>\n",
      " > affiliation: list<item: struct<name: string, path: list<item: struct<ugent_id: string>>, ugent_id: string>>\n",
      " > keyword: list<item: string>\n",
      " > doi: list<item: string>\n",
      " > abstract: list<item: string>\n",
      " > abstract_full: list<item: struct<lang: string, text: string>>\n",
      " > created_by: struct<_id: string, affiliation: list<item: struct<name: string, path: list<item: struct<ugent_id: string>>, ugent_id: string>>, biblio_id: string, first_name: string, last_name: string, name: string, name_last_first: string, orcid_id: string, ugent_id: list<item: string>>\n",
      " > project: list<item: struct<_id: string, abstract: string, deleted: int64, end_date: string, eu_acronym: string, eu_call_id: string, eu_framework_programme: string, eu_id: string, gismo_id: string, iweto_id: string, publication_count: int64, start_date: string, title: string, ugent_id: list<item: string>>>\n",
      " > language: list<item: string>\n",
      " > jcr: struct<category: string, category_decile: int64, category_quartile: int64, category_rank: string, category_vigintile: int64, eigenfactor: double, immediacy_index: double, impact_factor: double, impact_factor_5yr: double, prev_category_decile: int64, prev_category_quartile: int64, prev_category_vigintile: int64, prev_impact_factor: double, total_cites: int64>\n",
      " > page: struct<count: string, first: string, last: string>\n",
      " > conference: struct<end_date: string, location: string, name: string, organizer: string, start_date: string>\n",
      " > issn: list<item: string>\n",
      " > cite: struct<apa: string, bof: string, chicago-author-date: string, fwo: string, ieee: string, mla: string, vancouver: string>\n",
      " > subject: list<item: string>\n",
      " > parent: struct<short_title: string, title: string>\n",
      " > source: struct<db: string, id: string, record: string>\n",
      " > editor: list<item: struct<_id: string, affiliation: list<item: struct<name: string, path: list<item: struct<ugent_id: string>>, ugent_id: string>>, biblio_id: string, first_name: string, last_name: string, name: string, name_last_first: string, orcid_id: string, ugent_id: list<item: string>>>\n",
      " > isbn: list<item: string>\n",
      " > vabb_year: list<item: string>\n",
      " > file: list<item: struct<_id: string, access: string, change: struct<on: string, to: string>, content_type: string, kind: string, name: string, publication_version: string, sha256: string, size: string, thumbnail_url: string, url: string>>\n",
      " > alternative_location: list<item: struct<access: string, kind: string, url: string>>\n",
      "Conversion complete.\n",
      "\n",
      "--- DataFrame Summary (Shape: (376538, 51) (rows, cols)) ---\n",
      "\n",
      "DUPLICATES\n",
      "\n",
      "Warning: Excluding unhashable columns from duplicate check: ['publisher', 'author', 'affiliation', 'keyword', 'doi', 'abstract', 'abstract_full', 'created_by', 'project', 'language', 'jcr', 'page', 'conference', 'issn', 'cite', 'subject', 'parent', 'source', 'editor', 'isbn', 'vabb_year', 'file', 'alternative_location']\n",
      "\n",
      "No duplicates found.\n",
      "--------------------\n",
      "\n",
      "Getting dataframe overview...\n",
      "                         missing#  missing%  unique#                                   sample_val placeholders                                                                                                                                                                                                                                                                                                                                                                             dtypes\n",
      "parent                      44559     11.83       -1  {'short_title': 'Dig. Tech. Pap.', 'titl...               struct<short_title: string, title: string>[pyarrow]                                                                                                                                                                                                                                                                                                                              \n",
      "publisher                  254760     67.66       -1  {'location': None, 'name': 'DataverseNO'...               struct<location: string, name: string>[pyarrow]                                                                                                                                                                                                                                                                                                                                  \n",
      "conference                 306263     81.34       -1  {'end_date': '2002-05-24', 'location': '...               struct<end_date: string, location: string, name: string, organizer: string, start_date: string>[pyarrow]                                                                                                                                                                                                                                                                         \n",
      "source                     255134     67.76       -1  {'db': 'aleph:pug01', 'id': '19093', 're...               struct<db: string, id: string, record: string>[pyarrow]                                                                                                                                                                                                                                                                                                                          \n",
      "page                        53006     14.08       -1  {'count': None, 'first': '534', 'last': ...               struct<count: string, first: string, last: string>[pyarrow]                                                                                                                                                                                                                                                                                                                      \n",
      "jcr                        250502     66.53       -1  {'category': 'OBSTETRICS & GYNECOLOGY', ...               struct<category: string, category_decile: int64, category_quartile: int64, category_rank: string, category_vigintile: int64, eigenfactor: double, immediacy_index: double, impact_factor: double, impact_factor_5yr: double, prev_category_decile: int64, prev_category_quartile: int64, prev_category_vigintile: int64, prev_impact_factor: double, total_cites: int64>[pyarrow]\n",
      "cite                          413      0.11       -1  {'apa': '  <div class=\"csl-entry\">Bruyne...               struct<apa: string, bof: string, chicago-author-date: string, fwo: string, ieee: string, mla: string, vancouver: string>[pyarrow]                                                                                                                                                                                                                                                \n",
      "created_by                  80160     21.29       -1  {'_id': 'F8ABF6F2-F0ED-11E1-A9DE-61C894A...               struct<_id: string, affiliation: list<item: struct<name: string, path: list<item: struct<ugent_id: string>>, ugent_id: string>>, biblio_id: string, first_name: string, last_name: string, name: string, name_last_first: string, orcid_id: string, ugent_id: list<item: string>>[pyarrow]                                                                                       \n",
      "vabb_id                    287830     76.44    88517                                c:vabb:189879               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "_id                             0      0.00   376538                   01HPHDH0QHZXK6QRKNGWBNE1QT               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "status                          0      0.00        1                                       public               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "volume                     157122     41.73     5557                                           33      ['999']  string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "conference_type            328506     87.24        5                                        other               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "vabb_type                  287830     76.44        5                                       VABB-1               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "article_type               192128     51.02        4                                     original               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "classification                413      0.11       13                                           C1               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "wos_type                   214569     56.98       83                                      Article               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "wos_id                     216277     57.44   160139                              000178256400009               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "article_number             335197     89.02    29002                                       T03009               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "additional_info            355926     94.53    12230  dissertation in part contains copyrighte...               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "misc_type                  345988     91.89       29                            editorialMaterial               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "pubmed_id                  355703     94.47    20818                                     21772250               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "series_title               357420     94.92     7369  International Archives of the History of...               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "biblio_id                       0      0.00   376538                   01HPHDH0QHZXK6QRKNGWBNE1QT               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "handle                          0      0.00   376538  http://hdl.handle.net/1854/LU-01HPHDH0QH...               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "date_created                    0      0.00   301290                          2024-02-13 14:21:54               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "date_updated                    0      0.00    82040                          2024-07-09 07:38:10               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "title                           0      0.00   366095  Replication Data for: Zooming in on the ...               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "issue                      203608     54.07     6856                                            1      ['999']  string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "type                            0      0.00        9                                 researchData               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "publication_status            413      0.11        3                                    published               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "copyright_statement        139528     37.06       10  Creative Commons Attribution-NonCommerci...               string[pyarrow]                                                                                                                                                                                                                                                                                                                                                                  \n",
      "affiliation                  4207      1.12       -1  [{'name': 'Department of Linguistics', '...               list<item: struct<name: string, path: list<item: struct<ugent_id: string>>, ugent_id: string>>[pyarrow]                                                                                                                                                                                                                                                                          \n",
      "abstract_full              237891     63.18       -1  [{'lang': 'eng', 'text': 'The dataset in...               list<item: struct<lang: string, text: string>>[pyarrow]                                                                                                                                                                                                                                                                                                                          \n",
      "alternative_location       348822     92.64       -1  [{'access': 'open', 'kind': 'fullText', ...               list<item: struct<access: string, kind: string, url: string>>[pyarrow]                                                                                                                                                                                                                                                                                                           \n",
      "editor                     328856     87.34       -1  [{'_id': None, 'affiliation': None, 'bib...               list<item: struct<_id: string, affiliation: list<item: struct<name: string, path: list<item: struct<ugent_id: string>>, ugent_id: string>>, biblio_id: string, first_name: string, last_name: string, name: string, name_last_first: string, orcid_id: string, ugent_id: list<item: string>>>[pyarrow]                                                                           \n",
      "author                       5511      1.46       -1  [{'_id': 'F8ABF6F2-F0ED-11E1-A9DE-61C894...               list<item: struct<_id: string, affiliation: list<item: struct<name: string, path: list<item: struct<ugent_id: string>>, ugent_id: string>>, biblio_id: string, credit_role: list<item: string>, first_name: string, last_name: string, name: string, name_last_first: string, orcid_id: string, ugent_id: list<item: string>>>[pyarrow]                                          \n",
      "file                       139941     37.17       -1  [{'_id': '1010130', 'access': 'restricte...               list<item: struct<_id: string, access: string, change: struct<on: string, to: string>, content_type: string, kind: string, name: string, publication_version: string, sha256: string, size: string, thumbnail_url: string, url: string>>[pyarrow]                                                                                                                                \n",
      "project                    352989     93.75       -1  [{'_id': '01P12016', 'abstract': '<p>The...               list<item: struct<_id: string, abstract: string, deleted: int64, end_date: string, eu_acronym: string, eu_call_id: string, eu_framework_programme: string, eu_id: string, gismo_id: string, iweto_id: string, publication_count: int64, start_date: string, title: string, ugent_id: list<item: string>>>[pyarrow]                                                               \n",
      "isbn                       309902     82.30       -1  ['9781876346416', '9781876346454', '9781...               list<item: string>[pyarrow]                                                                                                                                                                                                                                                                                                                                                      \n",
      "vabb_year                  277946     73.82       -1                             ['2009', '2010']               list<item: string>[pyarrow]                                                                                                                                                                                                                                                                                                                                                      \n",
      "language                      208      0.06       -1                               ['eng', 'lat']               list<item: string>[pyarrow]                                                                                                                                                                                                                                                                                                                                                      \n",
      "abstract                   237891     63.18       -1  ['The dataset includes an annotated corp...               list<item: string>[pyarrow]                                                                                                                                                                                                                                                                                                                                                      \n",
      "subject                     21196      5.63       -1               ['Technology and Engineering']               list<item: string>[pyarrow]                                                                                                                                                                                                                                                                                                                                                      \n",
      "doi                        231847     61.57       -1                          ['10.18710/SZZDLI']               list<item: string>[pyarrow]                                                                                                                                                                                                                                                                                                                                                      \n",
      "issn                       148186     39.35       -1                                ['0097-966X']               list<item: string>[pyarrow]                                                                                                                                                                                                                                                                                                                                                      \n",
      "keyword                    217809     57.85       -1  ['French', 'ingressive', 'selection-theo...               list<item: string>[pyarrow]                                                                                                                                                                                                                                                                                                                                                      \n",
      "publication_status_sort       413      0.11        3                                            2               int64[pyarrow]                                                                                                                                                                                                                                                                                                                                                                   \n",
      "year                         5812      1.54      129                                         2024               int64[pyarrow]                                                                                                                                                                                                                                                                                                                                                                   \n",
      "vabb_approved              287830     76.44        2                                        False               bool[pyarrow]                                                                                                                                                                                                                                                                                                                                                                    \n",
      "external                        0      0.00        2                                        False               bool[pyarrow]                                                                                                                                                                                                                                                                                                                                                                    \n",
      "\n",
      "\n",
      "--------------------\n",
      "\n",
      "[Mixed Type Report]\n",
      "No mixed data types found (All object columns are homogeneous).\n",
      "--------------------\n",
      "\n",
      "Checking unhashable column structures...\n",
      "\n",
      "--- Deep Structure & Stats (Sample n=5000) ---\n",
      "Column 'publisher':\n",
      "  - Object (Dict) with keys:\n",
      "    * location:                 string          | 830 unique | sample: Turnhout, Belgique                       | (DENSE)\n",
      "    * name:                     string          | 2209 unique | sample: PERGAMON-ELSEVIER SCIENCE LTD            | (DENSE)\n",
      "\n",
      "Column 'author':\n",
      "  - List of:\n",
      "    - Object (Dict) with keys:\n",
      "      * _id:                      string          | 5825 unique | sample: F4AA5ECC-F0ED-11E1-A9DE-61C894A0A6B4     | (CATEGORY)\n",
      "      * affiliation:\n",
      "          - List of:\n",
      "            - Object (Dict) with keys:\n",
      "              * name:                     string          |   5 unique | sample: Ghent University                         | (CATEGORY)\n",
      "              * path:\n",
      "                  - List of:\n",
      "                    - Object (Dict) with keys:\n",
      "                      * ugent_id:                 string          | 212 unique | sample: UGent                                    | (CATEGORY)\n",
      "              * ugent_id:                 string          | 199 unique | sample: LW07                                     | (CATEGORY)\n",
      "      * biblio_id:                string          | 5825 unique | sample: F4AA5ECC-F0ED-11E1-A9DE-61C894A0A6B4     | (CATEGORY)\n",
      "      * credit_role:\n",
      "          - List of:\n",
      "            string          |  16 unique | sample: first_author                             | (CATEGORY)\n",
      "      * first_name:               string          | 8362 unique | sample: Benjamin                                 | (DENSE)\n",
      "      * last_name:                string          | 24007 unique | sample: Biebuyck                                 | (DENSE)\n",
      "      * name:                     string          | 34377 unique | sample: Benjamin Biebuyck                        | (DENSE)\n",
      "      * name_last_first:          string          | 34489 unique | sample: Biebuyck, Benjamin                       | (DENSE)\n",
      "      * orcid_id:                 string          | 2720 unique | sample: 0000-0002-2059-7495                      | (CATEGORY)\n",
      "      * ugent_id:\n",
      "          - List of:\n",
      "            string          | 11444 unique | sample: 801000881646                             | (DENSE)\n",
      "\n",
      "Column 'affiliation':\n",
      "  - List of:\n",
      "    - Object (Dict) with keys:\n",
      "      * name:                     string          | 219 unique | sample: Department of Materials Science and E... | (CATEGORY)\n",
      "      * path:\n",
      "          - List of:\n",
      "            - Object (Dict) with keys:\n",
      "              * ugent_id:                 string          | 221 unique | sample: UGent                                    | (CATEGORY)\n",
      "      * ugent_id:                 string          | 218 unique | sample: TW10                                     | (CATEGORY)\n",
      "\n",
      "Column 'keyword':\n",
      "  - List of:\n",
      "    string          | 30394 unique | sample: BPM, Performance Appraisals and Rewar... | (DENSE)\n",
      "\n",
      "Column 'doi':\n",
      "  - List of:\n",
      "    string          | 5000 unique | sample: 10.1109/LCOMM.2020.2990950               | (ID/TEXT)\n",
      "\n",
      "Column 'abstract':\n",
      "  - List of:\n",
      "    string          | 5029 unique | sample: Zeolieten zijn alomtegenwoordige kata... | (ID/TEXT)\n",
      "\n",
      "Column 'abstract_full':\n",
      "  - List of:\n",
      "    - Object (Dict) with keys:\n",
      "      * lang:                     string          |  13 unique | sample: eng                                      | (CATEGORY)\n",
      "      * text:                     string          | 5036 unique | sample: The voices of women in recovery have ... | (ID/TEXT)\n",
      "\n",
      "Column 'created_by':\n",
      "  - Object (Dict) with keys:\n",
      "    * _id:                      string          | 2423 unique | sample: F6CD6ABE-F0ED-11E1-A9DE-61C894A0A6B4     | (DENSE)\n",
      "    * affiliation:\n",
      "        - List of:\n",
      "          - Object (Dict) with keys:\n",
      "            * name:                     string          |   3 unique | sample: Ghent University                         | (CATEGORY)\n",
      "            * path:\n",
      "                - List of:\n",
      "                  - Object (Dict) with keys:\n",
      "                    * ugent_id:                 string          | 158 unique | sample: UGent                                    | (CATEGORY)\n",
      "            * ugent_id:                 string          | 145 unique | sample: LW07                                     | (CATEGORY)\n",
      "    * biblio_id:                string          | 2423 unique | sample: F6CD6ABE-F0ED-11E1-A9DE-61C894A0A6B4     | (DENSE)\n",
      "    * first_name:               string          | 1128 unique | sample: Lars                                     | (DENSE)\n",
      "    * last_name:                string          | 1955 unique | sample: Bernaerts                                | (DENSE)\n",
      "    * name:                     string          | 2413 unique | sample: Lars Bernaerts                           | (DENSE)\n",
      "    * name_last_first:          string          | 2413 unique | sample: Bernaerts, Lars                          | (DENSE)\n",
      "    * orcid_id:                 string          | 1507 unique | sample: 0000-0001-8211-4551                      | (DENSE)\n",
      "    * ugent_id:\n",
      "        - List of:\n",
      "          string          | 4814 unique | sample: 001998154126                             | (DENSE)\n",
      "\n",
      "Column 'project':\n",
      "  - List of:\n",
      "    - Object (Dict) with keys:\n",
      "      * _id:                      string          | 2875 unique | sample: 174G09114                                | (DENSE)\n",
      "      * abstract:                 string          | 2678 unique | sample: <p>The Center for Nano- and Biophoton... | (DENSE)\n",
      "      * deleted:                  int64           |   2 unique | sample: NULL                                     | (CATEGORY)\n",
      "      * end_date:                 string          | 376 unique | sample: 28/02/18                                 | (CATEGORY)\n",
      "      * eu_acronym:               string          | 145 unique | sample: FORMICA                                  | (CATEGORY)\n",
      "      * eu_call_id:               string          | 104 unique | sample: H20.ERC.2018.0002.01                     | (CATEGORY)\n",
      "      * eu_framework_programme:   string          |   3 unique | sample: H2020                                    | (CATEGORY)\n",
      "      * eu_id:                    string          | 355 unique | sample: 30188225                                 | (CATEGORY)\n",
      "      * gismo_id:                 string          | 2838 unique | sample: e8ded5bb-d2f9-4991-ae4c-e97d04f71cd4     | (DENSE)\n",
      "      * iweto_id:                 string          | 2875 unique | sample: 174G09114                                | (DENSE)\n",
      "      * publication_count:        int64           | 171 unique | sample: 4                                        | (CATEGORY)\n",
      "      * start_date:               string          | 300 unique | sample: 01/03/14                                 | (CATEGORY)\n",
      "      * title:                    string          | 2813 unique | sample: ESFRI project LIFEWATCH                  | (DENSE)\n",
      "      * ugent_id:\n",
      "          - List of:\n",
      "            string          |  36 unique | sample: 801001389985                             | (CATEGORY)\n",
      "\n",
      "Column 'language':\n",
      "  - List of:\n",
      "    string          |  18 unique | sample: dut                                      | (CATEGORY)\n",
      "\n",
      "Column 'jcr':\n",
      "  - Object (Dict) with keys:\n",
      "    * category:                 string          | 225 unique | sample: PSYCHOLOGY, MULTIDISCIPLINARY            | (CATEGORY)\n",
      "    * category_decile:          int64           |  11 unique | sample: 1                                        | (CATEGORY)\n",
      "    * category_quartile:        int64           |   5 unique | sample: 1                                        | (CATEGORY)\n",
      "    * category_rank:            string          | 3431 unique | sample: 6/218                                    | (DENSE)\n",
      "    * category_vigintile:       int64           |  21 unique | sample: 1                                        | (CATEGORY)\n",
      "    * eigenfactor:              double          | 2422 unique | sample: 0.02102                                  | (DENSE)\n",
      "    * immediacy_index:          double          | 1694 unique | sample: 1.3                                      | (DENSE)\n",
      "    * impact_factor:            double          | 3051 unique | sample: 12.3                                     | (DENSE)\n",
      "    * impact_factor_5yr:        double          | 2426 unique | sample: 15.5                                     | (DENSE)\n",
      "    * prev_category_decile:     int64           |  11 unique | sample: 1                                        | (CATEGORY)\n",
      "    * prev_category_quartile:   int64           |   5 unique | sample: 1                                        | (CATEGORY)\n",
      "    * prev_category_vigintile:  int64           |  21 unique | sample: 1                                        | (CATEGORY)\n",
      "    * prev_impact_factor:       double          | 3073 unique | sample: 16.4                                     | (DENSE)\n",
      "    * total_cites:              int64           | 3667 unique | sample: 34832                                    | (DENSE)\n",
      "\n",
      "Column 'page':\n",
      "  - Object (Dict) with keys:\n",
      "    * count:                    string          | 1128 unique | sample: 221                                      | (DENSE)\n",
      "    * first:                    string          | 1315 unique | sample: 4385                                     | (DENSE)\n",
      "    * last:                     string          | 1341 unique | sample: 4396                                     | (DENSE)\n",
      "\n",
      "Column 'conference':\n",
      "  - Object (Dict) with keys:\n",
      "    * end_date:                 string          | 2871 unique | sample: 2014-11-18                               | (DENSE)\n",
      "    * location:                 string          | 1698 unique | sample: St Niklaas                               | (DENSE)\n",
      "    * name:                     string          | 4576 unique | sample: De levensverzekering : wat u als boek... | (ID/TEXT)\n",
      "    * organizer:                string          | 678 unique | sample: European Society of Toxicologic Patho... | (DENSE)\n",
      "    * start_date:               string          | 3069 unique | sample: 2014-11-18                               | (DENSE)\n",
      "\n",
      "Column 'issn':\n",
      "  - List of:\n",
      "    string          | 3911 unique | sample: 1876-6102                                | (DENSE)\n",
      "\n",
      "Column 'cite':\n",
      "  - Object (Dict) with keys:\n",
      "    * apa:                      string          | 5000 unique | sample:   <div class=\"csl-entry\">Inzé, D., Fe... | (ID/TEXT)\n",
      "    * bof:                      string          | 4985 unique | sample:   <div class=\"csl-entry\">Inzé, Dirk, ... | (ID/TEXT)\n",
      "    * chicago-author-date:      string          | 4999 unique | sample:   <div class=\"csl-entry\">Inzé, Dirk, ... | (ID/TEXT)\n",
      "    * fwo:                      string          | 4999 unique | sample:   <div class=\"csl-entry\">Inzé, Dirk, ... | (ID/TEXT)\n",
      "    * ieee:                     string          | 5000 unique | sample:   <div class=\"csl-entry\">     <div cl... | (ID/TEXT)\n",
      "    * mla:                      string          | 4999 unique | sample:   <div class=\"csl-entry\">Inzé, Dirk, ... | (ID/TEXT)\n",
      "    * vancouver:                string          | 4999 unique | sample:   <div class=\"csl-entry\">     <div cl... | (ID/TEXT)\n",
      "\n",
      "Column 'subject':\n",
      "  - List of:\n",
      "    string          |  20 unique | sample: Law and Political Science                | (CATEGORY)\n",
      "\n",
      "Column 'parent':\n",
      "  - Object (Dict) with keys:\n",
      "    * short_title:              string          | 2156 unique | sample: Indian j. med. ethics                    | (DENSE)\n",
      "    * title:                    string          | 3897 unique | sample: INDIAN JOURNAL OF MEDICAL ETHICS         | (DENSE)\n",
      "\n",
      "Column 'source':\n",
      "  - Object (Dict) with keys:\n",
      "    * db:                       string          |   8 unique | sample: aleph:pug01                              | (CATEGORY)\n",
      "    * id:                       string          | 4110 unique | sample: 44940                                    | (DENSE)\n",
      "    * record:                   string          | 4981 unique | sample: 000044940 FMT   L BK 000044940 LDR   ... | (ID/TEXT)\n",
      "\n",
      "Column 'editor':\n",
      "  - List of:\n",
      "    - Object (Dict) with keys:\n",
      "      * _id:                      string          | 1270 unique | sample: 40643f2f-2303-11ec-ac25-b20a320d09f3     | (CATEGORY)\n",
      "      * affiliation:\n",
      "          - List of:\n",
      "            - Object (Dict) with keys:\n",
      "              * name:                     string          |   3 unique | sample: Ghent University                         | (CATEGORY)\n",
      "              * path:\n",
      "                  - List of:\n",
      "                    - Object (Dict) with keys:\n",
      "                      * ugent_id:                 string          | 142 unique | sample: UGent                                    | (CATEGORY)\n",
      "              * ugent_id:                 string          | 129 unique | sample: LW07                                     | (CATEGORY)\n",
      "      * biblio_id:                string          | 1270 unique | sample: 40643f2f-2303-11ec-ac25-b20a320d09f3     | (CATEGORY)\n",
      "      * first_name:               string          | 3949 unique | sample: Paul                                     | (DENSE)\n",
      "      * last_name:                string          | 7985 unique | sample: Mathis                                   | (DENSE)\n",
      "      * name:                     string          | 9554 unique | sample: Paul Mathis                              | (DENSE)\n",
      "      * name_last_first:          string          | 9558 unique | sample: Mathis, Paul                             | (DENSE)\n",
      "      * orcid_id:                 string          | 678 unique | sample: 0000-0001-8160-8453                      | (CATEGORY)\n",
      "      * ugent_id:\n",
      "          - List of:\n",
      "            string          | 2269 unique | sample: 802003775356                             | (DENSE)\n",
      "\n",
      "Column 'isbn':\n",
      "  - List of:\n",
      "    string          | 5332 unique | sample: 9781119789017                            | (ID/TEXT)\n",
      "\n",
      "Column 'vabb_year':\n",
      "  - List of:\n",
      "    string          |  17 unique | sample: 2018                                     | (CATEGORY)\n",
      "\n",
      "Column 'file':\n",
      "  - List of:\n",
      "    - Object (Dict) with keys:\n",
      "      * _id:                      string          | 5754 unique | sample: 8699124                                  | (ID/TEXT)\n",
      "      * access:                   string          |   3 unique | sample: restricted                               | (CATEGORY)\n",
      "      * change:\n",
      "          - Object (Dict) with keys:\n",
      "            * on:                       string          |  54 unique | sample:                                          | (CATEGORY)\n",
      "            * to:                       string          |   3 unique | sample:                                          | (CATEGORY)\n",
      "      * content_type:             string          |  29 unique | sample: application/pdf                          | (CATEGORY)\n",
      "      * kind:                     string          |   7 unique | sample: fullText                                 | (CATEGORY)\n",
      "      * name:                     string          | 5059 unique | sample: Martinez_et_al._2019_-_New_British_Bo... | (DENSE)\n",
      "      * publication_version:      string          |   5 unique | sample: publishedVersion                         | (CATEGORY)\n",
      "      * sha256:                   string          | 5744 unique | sample: 261a6af9bbaba891027fe4e95bc0974044dfc... | (ID/TEXT)\n",
      "      * size:                     string          | 5735 unique | sample: 720921                                   | (ID/TEXT)\n",
      "      * thumbnail_url:            string          | 5148 unique | sample: https://biblio.ugent.be/publication/8... | (DENSE)\n",
      "      * url:                      string          | 5424 unique | sample: https://biblio.ugent.be/publication/8... | (ID/TEXT)\n",
      "\n",
      "Column 'alternative_location':\n",
      "  - List of:\n",
      "    - Object (Dict) with keys:\n",
      "      * access:                   string          |   1 unique | sample: open                                     | (CONSTANT)\n",
      "      * kind:                     string          |   1 unique | sample: fullText                                 | (CONSTANT)\n",
      "      * url:                      string          | 5069 unique | sample: http://www.mdpi.com/1996-1073/9/6/450    | (ID/TEXT)\n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "Dataframe cleaner initialized, working on copy\n",
      "Showing all rows, set back with pd.set_option('display.max_rows', 10 idk)\n",
      "--- Auto-Inferring Schema (Sample n=1000) ---\n",
      "  > Detected 'promoter' as LIST\n",
      "  > Detected 'themes' as LIST\n",
      "  > Detected 'keywords' as LIST\n",
      "  > Detected 'authors' as LIST\n",
      " applying 19 overrides to auto schema\n",
      "--- Enforcing Schema on 19 columns ---\n",
      "\n",
      "[Cleaning Report] Values converted to NaN:\n",
      "\n",
      "Column               | Total  | Regex Match | Type Mismatch | Detected Garbage\n",
      "----------------------------------------------------------------------------------------------------\n",
      "title                | 1      | 1           | 0             | ['/']\n",
      "themes               | 719    | 0           | 719           | []\n",
      "keywords             | 153    | 0           | 153           | []\n",
      "text_homepage        | 1      | 1           | 0             | ['/']\n",
      "Dropped columns (> 95.0% missing): ['abstract', 'language_abstract', 'language_full', 'pages', 'chapters', 'type']\n",
      "Dropped 0 duplicates.\n",
      "Step 0: Checking for mixed types before conversion...\n",
      "Step 1: Auto converting to PyArrow-backed types...\n",
      "id               string[pyarrow]\n",
      "title            string[pyarrow]\n",
      "college          string[pyarrow]\n",
      "year              int64[pyarrow]\n",
      "promoter                  object\n",
      "themes                    object\n",
      "keywords                  object\n",
      "text_homepage    string[pyarrow]\n",
      "page_link        string[pyarrow]\n",
      "download_link    string[pyarrow]\n",
      "downloaded         bool[pyarrow]\n",
      "source           string[pyarrow]\n",
      "authors                   object\n",
      "dtype: object\n",
      "Step 2: converting object types\n",
      " > promoter: list<item: string>\n",
      " > themes: list<item: string>\n",
      " > keywords: list<item: string>\n",
      " > authors: list<item: string>\n",
      "Conversion complete.\n",
      "\n",
      "--- DataFrame Summary (Shape: (4181, 13) (rows, cols)) ---\n",
      "\n",
      "DUPLICATES\n",
      "\n",
      "Warning: Excluding unhashable columns from duplicate check: ['promoter', 'themes', 'keywords', 'authors']\n",
      "\n",
      "No duplicates found.\n",
      "--------------------\n",
      "\n",
      "Getting dataframe overview...\n",
      "               missing#  missing%  unique#                                   sample_val placeholders                       dtypes\n",
      "id                    0      0.00     4181                                            0      ['999']  string[pyarrow]            \n",
      "title                 1      0.02     4167  China & India: verleden, heden en toekom...               string[pyarrow]            \n",
      "college               0      0.00       19                       Universiteit Antwerpen               string[pyarrow]            \n",
      "text_homepage        14      0.33     4085  BRIC, BRICS, BASIC, … zijn letterwoorden...               string[pyarrow]            \n",
      "page_link             0      0.00     4181  https://scriptiebank.be/scriptie/2011/ta...               string[pyarrow]            \n",
      "download_link        96      2.30     4085  https://scriptiebank.be/file/14819/downl...               string[pyarrow]            \n",
      "source                0      0.00        1                                 scriptiebank               string[pyarrow]            \n",
      "promoter              0      0.00       -1                   ['Prof. Dr. Jan Melissen']               list<item: string>[pyarrow]\n",
      "themes              719     17.20       -1  ['Economische en toegepaste economische ...               list<item: string>[pyarrow]\n",
      "keywords            153      3.66       -1                                 ['economie']               list<item: string>[pyarrow]\n",
      "authors               0      0.00       -1                          ['Tim JJ Nelissen']               list<item: string>[pyarrow]\n",
      "year                  0      0.00       10                                         2011               int64[pyarrow]             \n",
      "downloaded           96      2.30        2                                         True               bool[pyarrow]              \n",
      "\n",
      "\n",
      "--------------------\n",
      "\n",
      "[Mixed Type Report]\n",
      "No mixed data types found (All object columns are homogeneous).\n",
      "--------------------\n",
      "\n",
      "Checking unhashable column structures...\n",
      "\n",
      "--- Deep Structure & Stats (Sample n=5000) ---\n",
      "Column 'promoter':\n",
      "  - List of:\n",
      "    string          | 4267 unique | sample: Prof. Dr. Jan Melissen                   | (DENSE)\n",
      "\n",
      "Column 'themes':\n",
      "  - List of:\n",
      "    string          |  44 unique | sample: Economische en toegepaste economische... | (CATEGORY)\n",
      "\n",
      "Column 'keywords':\n",
      "  - List of:\n",
      "    string          | 8837 unique | sample: economie                                 | (DENSE)\n",
      "\n",
      "Column 'authors':\n",
      "  - List of:\n",
      "    string          | 4083 unique | sample: Tim JJ Nelissen                          | (ID/TEXT)\n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "Step 1: Identifying candidate title pairs...\n",
      " -> Found 323 candidate row pairs based on Title.\n",
      "Step 2: Verifying Authors and Resolving...\n",
      " -> Marked 16 rows for removal.\n",
      " -> Marked 16 rows to keep (as the 'better' versions).\n",
      "\n",
      "Step 3: Checking Unaccounted Author Duplicates...\n",
      "Cleaned 'text_homepage': Removed 849 values shorter than 100 chars.\n",
      "Step 0: Checking for mixed types before conversion...\n",
      "Step 1: Auto converting to PyArrow-backed types...\n",
      "id                           string[pyarrow]\n",
      "title                        string[pyarrow]\n",
      "college                      string[pyarrow]\n",
      "year                          int64[pyarrow]\n",
      "promoter         list<item: string>[pyarrow]\n",
      "themes           list<item: string>[pyarrow]\n",
      "keywords         list<item: string>[pyarrow]\n",
      "text_homepage                string[pyarrow]\n",
      "page_link                    string[pyarrow]\n",
      "download_link                string[pyarrow]\n",
      "downloaded                     bool[pyarrow]\n",
      "source                       string[pyarrow]\n",
      "authors          list<item: string>[pyarrow]\n",
      "dtype: object\n",
      "Step 2: converting object types\n",
      " > promoter: list<item: string>\n",
      " > themes: list<item: string>\n",
      " > keywords: list<item: string>\n",
      " > authors: list<item: string>\n",
      "Conversion complete.\n",
      "idx: (4181, 4165)\n",
      "id: (np.int64(4180), '4180')\n"
     ]
    }
   ],
   "source": [
    "# scriptiebank has semi duplicate rows, we will remove them and keep the most complete ones\n",
    "# cleaning of both happens in src/clean.py\n",
    "\n",
    "%run 'src/clean.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1d4fec",
   "metadata": {},
   "source": [
    "Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd352a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge metadata frames\n",
    "    # update source & download link & download status + basic info...\n",
    "    # update archive\n",
    "        # scraper download?\n",
    "    # AFTER PARSE\n",
    "        # abstract / full language\n",
    "        # paper structure\n",
    "            # parse md files, toc compare with json\n",
    "        # text in files / other csv (prob csv)\n",
    "\n",
    "# full cleanup and merge: clean_merge.py\n",
    "    # download OK\n",
    "    # clean json -> parquet OK\n",
    "    # clean csv  -> parquet\n",
    "    # selection parquet\n",
    "\n",
    "\n",
    "%run 'src/merge.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f56ca3",
   "metadata": {},
   "source": [
    "preparing scriptiebank metadata for merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c694b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "df_s = pd.read_csv(Path('data/metadata copy.csv'))\n",
    "df_s['abstract'] = pd.NA\n",
    "df_s['language'] = pd.NA\n",
    "df_s['pages'] = pd.NA\n",
    "df_s['chapters'] = pd.NA\n",
    "df_s['type'] = pd.NA\n",
    "df_s['authors'] = [[f\"{first} {last}\"] for first, last in zip(df_s['first_name'], df_s['last_name'])]\n",
    "df_s = df_s.drop(columns=['first_name', 'last_name'])\n",
    "\n",
    "\n",
    "# we will parse the marker output later to add chapters, language, type and pages\n",
    "# save\n",
    "df_s.to_csv('data/metadata.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339443df",
   "metadata": {},
   "source": [
    "select rows to add and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713dac32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Added 10859 rows.\n",
      "Columns in new dataframe: ['id', 'title', 'affiliation', 'year', 'promoter', 'themes', 'keywords', 'text_homepage', 'page_link', 'download_link', 'downloaded', 'source', 'abstract', 'language', 'pages', 'chapters', 'type', 'authors']\n"
     ]
    }
   ],
   "source": [
    "''' selecting from ugent and merging datasets '''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.read_csv(Path('data/metadata.csv'))\n",
    "df2 = pd.read_parquet(Path('data/ugent_datadump/ugent_cleaned.parquet'))\n",
    "\n",
    "# --- HELPERS ---\n",
    "\n",
    "def get_open_access_link(file_list):\n",
    "    \"\"\"Returns URL if access is open, else None.\"\"\"\n",
    "    if isinstance(file_list, (list, np.ndarray)):\n",
    "        for f in file_list:\n",
    "            if isinstance(f, dict) and f.get('access') == 'open':\n",
    "                return f.get('url')\n",
    "    return None\n",
    "\n",
    "def check_metadata_dutch(lang_list):\n",
    "    \"\"\"Returns True if 'nl', 'dut', or 'nld' is in the language list.\"\"\"\n",
    "    if isinstance(lang_list, (list, np.ndarray)):\n",
    "        clean = [l for l in lang_list if isinstance(l, str)]\n",
    "        return any(l in ['nl', 'dut', 'nld'] for l in clean)\n",
    "    return False\n",
    "\n",
    "def extract_dutch_from_full(abs_full):\n",
    "    \"\"\"Scans abstract_full for Dutch text.\"\"\"\n",
    "    if isinstance(abs_full, (list, np.ndarray)):\n",
    "        for item in abs_full:\n",
    "            if isinstance(item, dict):\n",
    "                lang = item.get('lang', '').lower()\n",
    "                if lang in ['nl', 'dut', 'nld']:\n",
    "                    return item.get('text', '')\n",
    "    return None\n",
    "\n",
    "def get_fallback_abstract(row):\n",
    "    \"\"\"Fallback logic for abstracts.\"\"\"\n",
    "    # 1. Main Abstract\n",
    "    ab_main = row.get('abstract')\n",
    "    if isinstance(ab_main, (list, np.ndarray)) and len(ab_main) > 0:\n",
    "        if isinstance(ab_main[0], str) and ab_main[0].strip():\n",
    "            return ab_main[0]\n",
    "    elif isinstance(ab_main, str) and ab_main.strip():\n",
    "        return ab_main\n",
    "        \n",
    "    # 2. Any abstract_full\n",
    "    ab_full = row.get('abstract_full')\n",
    "    if isinstance(ab_full, (list, np.ndarray)) and len(ab_full) > 0:\n",
    "        if isinstance(ab_full[0], dict):\n",
    "            return ab_full[0].get('text', '')\n",
    "    return \"\"\n",
    "\n",
    "def process_authors(auth_list):\n",
    "    \"\"\"Extracts author names from list of dicts.\"\"\"\n",
    "    if not isinstance(auth_list, (list, np.ndarray)):\n",
    "        return []\n",
    "    result = []\n",
    "    for a in auth_list:\n",
    "        if isinstance(a, dict):\n",
    "            fn = a.get('first_name') or \"\"\n",
    "            ln = a.get('last_name') or \"\"\n",
    "            full = f\"{fn} {ln}\".strip()\n",
    "            if full:\n",
    "                result.append(full)\n",
    "    return result\n",
    "\n",
    "\n",
    "# unused \n",
    "def process_affiliation(aff_list):\n",
    "    \"\"\"\n",
    "    Extracts the 'name' from the first affiliation dictionary.\n",
    "    Input sample: [{'name': 'Department of...', 'ugent_id': '...'}]\n",
    "    \"\"\"\n",
    "    if isinstance(aff_list, (list, np.ndarray)) and len(aff_list) > 0:\n",
    "        first_item = aff_list[0]\n",
    "        if isinstance(first_item, dict):\n",
    "            return first_item.get('name')\n",
    "    return None\n",
    "\n",
    "# --- MAIN PROCESS ---\n",
    "\n",
    "# 1. FILTER YEAR\n",
    "df_work = df2.copy()\n",
    "df_work['year_clean'] = pd.to_numeric(df_work['year'], errors='coerce')\n",
    "df_work = df_work[df_work['year_clean'].between(2000, 2022)]\n",
    "\n",
    "if df_work.empty:\n",
    "    print(\"No entries found in year range.\")\n",
    "else:\n",
    "    # 2. CALCULATE CONDITIONS\n",
    "    df_work['download_link'] = df_work['file'].map(get_open_access_link)\n",
    "    is_open_access = df_work['download_link'].notna() \n",
    "    is_meta_dutch = df_work['language'].map(check_metadata_dutch)\n",
    "    \n",
    "    df_work['dutch_full_text'] = df_work['abstract_full'].map(extract_dutch_from_full)\n",
    "    has_dutch_full = df_work['dutch_full_text'].notna() & (df_work['dutch_full_text'] != \"\")\n",
    "    \n",
    "    # 3. APPLY SELECTION CRITERIA\n",
    "    keep_mask = (is_meta_dutch & is_open_access) | has_dutch_full\n",
    "    df_work = df_work[keep_mask].copy()\n",
    "    \n",
    "    if df_work.empty:\n",
    "        print(\"No rows matched the selection criteria.\")\n",
    "    else:\n",
    "        # 4. PREPARE FINAL COLUMNS\n",
    "        \n",
    "        # Complex Transformations\n",
    "        df_work['final_authors'] = df_work['author'].map(process_authors)\n",
    "        df_work['final_affiliation'] = df_work['affiliation'].map(process_affiliation)\n",
    "        \n",
    "        df_work['final_abstract'] = df_work.apply(\n",
    "            lambda r: r['dutch_full_text'] if (pd.notna(r['dutch_full_text']) and r['dutch_full_text'] != \"\") \n",
    "            else get_fallback_abstract(r), \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # 5. BUILD RESULT DATAFRAME\n",
    "        df_final = pd.DataFrame({\n",
    "            'id': df_work['_id'].combine_first(df_work['biblio_id']), # change to idx\n",
    "            'title': df_work['title'],\n",
    "            'year': df_work['year_clean'].astype(int),\n",
    "            'page_link': df_work['handle'],\n",
    "            'download_link': df_work['download_link'], \n",
    "            'authors': df_work['final_authors'],\n",
    "            'affiliation': df_work['affiliation'], \n",
    "            'themes': df_work['subject'],              \n",
    "            'keywords': df_work['keyword'],              \n",
    "            'abstract': df_work['final_abstract'],\n",
    "            'language': 'nl',\n",
    "            'source': 'ugent_biblio',\n",
    "            'downloaded': False,\n",
    "\n",
    "        })\n",
    "\n",
    "        # 6. PREPARE DF1\n",
    "        df1_clean = df1.rename(columns={'college': 'affiliation'})\n",
    "        \n",
    "        # 7. MERGE\n",
    "        start_idx = df1_clean.index[-1] + 1 if not df1_clean.empty else 0\n",
    "        df_final.index = range(start_idx, start_idx + len(df_final))\n",
    "        \n",
    "\n",
    "\n",
    "        df_final['id'] = df_final.index\n",
    "        \n",
    "        df_combined = pd.concat([df1_clean, df_final], axis=0)\n",
    "        \n",
    "        print(f\"Success! Added {len(df_final)} rows.\")\n",
    "        print(f\"Columns in new dataframe: {df_combined.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_parquet(Path('data/metadata.csv'), index=False, engine='pyarrow',compression='snappy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e376df00",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf2fc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing data at data/metadata.csv. Loading state.\n",
      "--- Starting scraper for: ugent ---\n",
      "Skipping Step 1: URL gathering.\n",
      "Skipping Step 2: Metadata scraping.\n",
      "\n",
      "Step 3: Checking for and downloading missing files...\n",
      "  -> Found 7362 items to download.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:   0%|          | 1/7362 [00:03<7:21:50,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error: 404 for URL https://scriptiebank.be/file/40856/download?token=Lzkut-1U. Full error: 404 Client Error: Not Found for url: https://scriptiebank.be/file/40856/download?token=Lzkut-1U\n",
      "  -> Download failed (bad response) for https://scriptiebank.be/file/40856/download?token=Lzkut-1U\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:   0%|          | 2/7362 [00:05<5:30:38,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error: 404 for URL https://scriptiebank.be/file/2428/download?token=6FNm. Full error: 404 Client Error: Not Found for url: https://scriptiebank.be/file/2428/download?token=6FNm\n",
      "  -> Download failed (bad response) for https://scriptiebank.be/file/2428/download?token=6FNm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:   0%|          | 3/7362 [00:09<6:41:24,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error: 404 for URL https://scriptiebank.be/file/60026/download?token=1zpr-lyU. Full error: 404 Client Error: Not Found for url: https://scriptiebank.be/file/60026/download?token=1zpr-lyU\n",
      "  -> Download failed (bad response) for https://scriptiebank.be/file/60026/download?token=1zpr-lyU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:   0%|          | 4/7362 [00:12<6:22:38,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error: 404 for URL https://scriptiebank.be/file/40982/download?token=809205eX. Full error: 404 Client Error: Not Found for url: https://scriptiebank.be/file/40982/download?token=809205eX\n",
      "  -> Download failed (bad response) for https://scriptiebank.be/file/40982/download?token=809205eX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:   0%|          | 5/7362 [00:14<5:49:42,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error: 404 for URL https://scriptiebank.be/file/108581/download?token=waJ5NYqX. Full error: 404 Client Error: Not Found for url: https://scriptiebank.be/file/108581/download?token=waJ5NYqX\n",
      "  -> Download failed (bad response) for https://scriptiebank.be/file/108581/download?token=waJ5NYqX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Files:   0%|          | 13/7362 [00:49<7:47:33,  3.82s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m scraper \u001b[38;5;241m=\u001b[39m BaseScraper(source_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mugent\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m scraper\u001b[38;5;241m.\u001b[39msource_name\n\u001b[0;32m----> 9\u001b[0m \u001b[43mscraper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgather_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mgather_urls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mdownload_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/internship/src/scrape.py:220\u001b[0m, in \u001b[0;36mBaseScraper.run\u001b[0;34m(self, gather_urls, gather_metadata, download_files)\u001b[0m\n\u001b[1;32m    217\u001b[0m     success_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdownload_link\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_filename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    221\u001b[0m     success_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    222\u001b[0m     existing_zip_files\u001b[38;5;241m.\u001b[39madd(safe_filename)\n",
      "File \u001b[0;32m~/internship/src/scrape.py:93\u001b[0m, in \u001b[0;36mBaseScraper._download_file\u001b[0;34m(self, download_url, filename_in_zip)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Downloads a file and writes it to the source's zip archive.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03mThe method attempts to download the content from `download_url`. It infers\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m:return: True if the download and save were successful, False otherwise.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     87\u001b[0m mime_to_extension \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/vnd.openxmlformats-officedocument.wordprocessingml.document\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocx\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/msword\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m }\n\u001b[0;32m---> 93\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mtimed_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  -> Download failed (bad response) for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdownload_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/internship/src/mu.py:1244\u001b[0m, in \u001b[0;36mtimed_request\u001b[0;34m(url, session, method, delay, timeout, headers, **kwargs)\u001b[0m\n\u001b[1;32m   1242\u001b[0m requester \u001b[38;5;241m=\u001b[39m session \u001b[38;5;28;01mif\u001b[39;00m session \u001b[38;5;28;01melse\u001b[39;00m requests\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1244\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1251\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/marker_full/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/marker_full/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/marker_full/lib/python3.10/site-packages/requests/sessions.py:724\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[1;32m    723\u001b[0m     gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_redirects(r, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 724\u001b[0m     history \u001b[38;5;241m=\u001b[39m [resp \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m gen]\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    726\u001b[0m     history \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/marker_full/lib/python3.10/site-packages/requests/sessions.py:724\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[1;32m    723\u001b[0m     gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_redirects(r, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 724\u001b[0m     history \u001b[38;5;241m=\u001b[39m [resp \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m gen]\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    726\u001b[0m     history \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/marker_full/lib/python3.10/site-packages/requests/sessions.py:265\u001b[0m, in \u001b[0;36mSessionRedirectMixin.resolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m req\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madapter_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     extract_cookies_to_jar(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcookies, prepared_request, resp\u001b[38;5;241m.\u001b[39mraw)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/marker_full/lib/python3.10/site-packages/requests/sessions.py:746\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 746\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/miniconda3/envs/marker_full/lib/python3.10/site-packages/requests/models.py:902\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 902\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/marker_full/lib/python3.10/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/marker_full/lib/python3.10/site-packages/urllib3/response.py:1091\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1090\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1091\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1094\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/marker_full/lib/python3.10/site-packages/urllib3/response.py:980\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 980\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/marker_full/lib/python3.10/site-packages/urllib3/response.py:904\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    901\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/marker_full/lib/python3.10/site-packages/urllib3/response.py:887\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 887\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/miniconda3/envs/marker_full/lib/python3.10/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/miniconda3/envs/marker_full/lib/python3.10/socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/marker_full/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/marker_full/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "''' download new '''\n",
    "# scraper download only\n",
    "from src.scrape import BaseScraper\n",
    "\n",
    "\n",
    "\n",
    "scraper = BaseScraper(source_name='ugent')\n",
    "scraper.source_name\n",
    "scraper.run(gather_metadata=False,gather_urls=False,download_files=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced8f976",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fbec7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8094\n"
     ]
    }
   ],
   "source": [
    "''' parsing scriptiebank with marker-pdf[full]: see src/marker_full.py '''\n",
    "# each pdf produces a json and md file\n",
    "\n",
    "ZIP_OUTPUT = Path(\"data/output_marker.zip\")\n",
    "with zipfile.ZipFile(ZIP_OUTPUT, 'r') as z_out:\n",
    "    print(len(z_out.namelist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd3e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' remove missing files from temp extract folder and rezip. '''\n",
    "# remove missing files (some files failed to convert) \n",
    "    # rerun with lower batch size?\n",
    "# remove _meta files from zip (if other one exists and identical)  (rerun produced duplicates)\n",
    "    # OR rename in temp folder\n",
    "    # output_marker.zip contains both normal .json and _meta.json file, they are identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ff914",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' check failed conversions and delete them in temp output '''\n",
    "\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "ZIP_INPUT = Path(\"data/archive.zip\")\n",
    "ZIP_OUTPUT = Path(\"data/output_marker.zip\")\n",
    "TARGET_DIR = Path(\"data/temp/marker_output\")\n",
    "missing_files = []\n",
    "\n",
    "\n",
    "def check_zip_vs_valid_folders(missing_files):\n",
    "    if not ZIP_INPUT.exists() or not TARGET_DIR.exists():\n",
    "        print(\"Zip file or Target Directory not found.\")\n",
    "        return\n",
    "\n",
    "    # 1. Get expected names from Zip (stems only)\n",
    "    zip_stems = set()\n",
    "    with zipfile.ZipFile(ZIP_INPUT, 'r') as z_in:\n",
    "        for filename in z_in.namelist():\n",
    "            if not filename.endswith('/'):\n",
    "                # 'document.txt' -> 'document'\n",
    "                zip_stems.add(Path(filename).stem)\n",
    "\n",
    "    # 2. Identify VALID folders on disk\n",
    "    # A folder is valid only if it contains at least one .md AND one .json file\n",
    "    valid_disk_folders = set()\n",
    "    \n",
    "    for folder in TARGET_DIR.iterdir():\n",
    "        if folder.is_dir():\n",
    "            # any() stops searching as soon as it finds one match, making it efficient\n",
    "            has_md = any(folder.glob(\"*.md\"))\n",
    "            has_json = any(folder.glob(\"*.json\"))\n",
    "            \n",
    "            if has_md and has_json:\n",
    "                valid_disk_folders.add(folder.name)\n",
    "\n",
    "    # 3. Compare: Items in Zip minus Valid Folders\n",
    "    # This catches folders that are completely missing AND folders that exist but are empty\n",
    "    missing_or_invalid = zip_stems - valid_disk_folders\n",
    "\n",
    "    print(f\"Items in Zip: {len(zip_stems)}\")\n",
    "    print(f\"Valid Folders (have md+json): {len(valid_disk_folders)}\")\n",
    "    print(f\"Missing / Empty folders: {len(missing_or_invalid)}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    if missing_or_invalid:\n",
    "        for name in sorted(missing_or_invalid):\n",
    "            missing_files.append(name)\n",
    "            # We check if the folder physically exists to give a helpful print message\n",
    "            folder_path = TARGET_DIR / name\n",
    "            if folder_path.exists() and folder_path.is_dir():\n",
    "                print(f\"[EMPTY] {name} (Exists but missing .md/.json)\")\n",
    "            else:\n",
    "                print(f\"[MISSING] {name}\")\n",
    "    else:\n",
    "        print(\"All items are present and contain the required files.\")\n",
    "\n",
    "        \n",
    "def cleanup_folders(folder_names_list):\n",
    "    if not folder_names_list:\n",
    "        print(\"No folders to delete.\")\n",
    "        return\n",
    "\n",
    "    print(f\"⚠ Starting deletion of {len(folder_names_list)} folders...\")\n",
    "\n",
    "    for folder_name in folder_names_list:\n",
    "        # Construct the full path\n",
    "        dir_to_delete = TARGET_DIR / folder_name\n",
    "\n",
    "        # Check existence to prevent crashes\n",
    "        if dir_to_delete.exists() and dir_to_delete.is_dir():\n",
    "            has_md = any(dir_to_delete.glob(\"*.md\"))\n",
    "            has_json = any(dir_to_delete.glob(\"*.json\"))\n",
    "            if not has_md and not has_json:\n",
    "                try:\n",
    "                    # rmtree deletes the folder AND all contents\n",
    "                    shutil.rmtree(dir_to_delete)\n",
    "                    print(f\"Deleted: {folder_name}\")\n",
    "                except OSError as e:\n",
    "                    print(f\"Error deleting {folder_name}: {e}\")\n",
    "            else:\n",
    "                print(f'{dir_to_delete} does have md: {has_md} or json: {has_json}')\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"Skipped: {folder_name} (Does not exist on disk)\")\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    check_zip_vs_valid_folders(missing_files)\n",
    "    #cleanup_folders(missing_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f543ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' meta files '''\n",
    "# CHECK FOR META FILES \n",
    "\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "def compare_meta_files(folder_path, zip_file_path):\n",
    "    \"\"\"\n",
    "    Compares files with '_meta' in a folder against their counterparts \n",
    "    inside a zip file (without '_meta').\n",
    "    \n",
    "    Returns: A list of filenames that do not match.\n",
    "    \"\"\"\n",
    "    mismatched_files = []\n",
    "    n_meta = 0\n",
    "\n",
    "    # Convert strings to Path objects\n",
    "    folder = Path(folder_path)\n",
    "    \n",
    "    # Check if paths exist\n",
    "    if not folder.exists():\n",
    "        print(f\"Error: Folder '{folder_path}' does not exist.\")\n",
    "        return []\n",
    "    if not Path(zip_file_path).exists():\n",
    "        print(f\"Error: Zip file '{zip_file_path}' does not exist.\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as z:\n",
    "            # Get a set of all filenames currently in the zip for fast lookup\n",
    "            zip_contents = set(z.namelist())\n",
    "            \n",
    "            # Iterate over files in the local folder\n",
    "            for local_file in folder.rglob('*'):\n",
    "                \n",
    "                # Filter for files containing \"_meta\" (ignoring directories)\n",
    "                if local_file.is_file() and \"_meta\" in local_file.name:\n",
    "                    n_meta += 1\n",
    "                    # Construct the expected zip filename\n",
    "                    # e.g., \"4125_meta.json\" -> \"4125.json\"\n",
    "                    target_zip_name = local_file.name.replace(\"_meta\", \"\")\n",
    "                    \n",
    "                    # Case 1: File does not exist in the zip\n",
    "                    if target_zip_name not in zip_contents:\n",
    "                        print(f\"Mismatch: '{target_zip_name}' is missing from the ZIP file.\")\n",
    "                        mismatched_files.append(local_file.name)\n",
    "                        continue\n",
    "                    \n",
    "                    # Case 2: Compare content\n",
    "                    # Read local file in binary mode\n",
    "                    local_data = local_file.read_bytes()\n",
    "                    # Read zip file in binary mode\n",
    "                    zip_data = z.read(target_zip_name)\n",
    "                    \n",
    "                    if local_data != zip_data:\n",
    "                        mismatched_files.append(local_file.name)\n",
    "\n",
    "    except zipfile.BadZipFile:\n",
    "        print(\"Error: The file provided is not a valid ZIP file.\")\n",
    "        return []\n",
    "\n",
    "    # Print results\n",
    "    if mismatched_files:\n",
    "        print(\"\\n--- The following files are not exactly the same ---\")\n",
    "        for fname in mismatched_files:\n",
    "            print(fname)\n",
    "    else:\n",
    "        print(\"\\nAll matching files are identical.\")\n",
    "    print(n_meta)\n",
    "\n",
    "    return mismatched_files\n",
    "\n",
    "# ==========================================\n",
    "# Example Usage\n",
    "# ==========================================\n",
    "# Change these paths to match your actual file locations\n",
    "folder_to_check = \"data/temp/marker_output\"\n",
    "zip_archive = \"data/output_marker.zip\"\n",
    "\n",
    "# Run the function\n",
    "compare_meta_files(folder_to_check, zip_archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa34d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' restore proper names '''\n",
    "\n",
    "def rename_meta_files(folder_path):\n",
    "    \"\"\"\n",
    "    Recursively finds files with '_meta' in their name within a folder\n",
    "    and renames them by removing the '_meta' part.\n",
    "    \"\"\"\n",
    "    folder = Path(folder_path)\n",
    "    \n",
    "    # Check if path exists\n",
    "    if not folder.exists():\n",
    "        print(f\"Error: Folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    renamed_count = 0\n",
    "\n",
    "    print(f\"Scanning '{folder_path}' for files to rename...\")\n",
    "\n",
    "    # Iterate over all files recursively\n",
    "    for local_file in folder.rglob('*'):\n",
    "        \n",
    "        # Check if it's a file and has \"_meta\" in the name\n",
    "        if local_file.is_file() and \"_meta\" in local_file.name:\n",
    "            \n",
    "            # Construct the new filename\n",
    "            # e.g., \"4125_meta.json\" -> \"4125.json\"\n",
    "            new_filename = local_file.name.replace(\"_meta\", \"\")\n",
    "            new_file_path = local_file.with_name(new_filename)\n",
    "            \n",
    "            try:\n",
    "                # Rename the file\n",
    "                local_file.rename(new_file_path)\n",
    "                print(f\"Renamed: {local_file.name} -> {new_filename}\")\n",
    "                renamed_count += 1\n",
    "            except OSError as e:\n",
    "                print(f\"Error renaming {local_file.name}: {e}\")\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Total files renamed: {renamed_count}\")\n",
    "\n",
    "# ==========================================\n",
    "# Example Usage\n",
    "# ==========================================\n",
    "folder_to_check = \"data/temp/marker_output\"\n",
    "\n",
    "# Run the function\n",
    "rename_meta_files(folder_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6140f55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>year</th>\n",
       "      <th>promoter</th>\n",
       "      <th>themes</th>\n",
       "      <th>keywords</th>\n",
       "      <th>text_homepage</th>\n",
       "      <th>page_link</th>\n",
       "      <th>download_link</th>\n",
       "      <th>downloaded</th>\n",
       "      <th>source</th>\n",
       "      <th>abstract</th>\n",
       "      <th>language</th>\n",
       "      <th>pages</th>\n",
       "      <th>chapters</th>\n",
       "      <th>type</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6385</th>\n",
       "      <td>6385</td>\n",
       "      <td>Verslag: het métier en de opleiding van de Ned...</td>\n",
       "      <td>[{'name': 'Department of Legal theory and lega...</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['History and Archaeology']</td>\n",
       "      <td>['Historiography' 'Education']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://hdl.handle.net/1854/LU-1173782</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>ugent_biblio</td>\n",
       "      <td>Report on a conference featuring the position ...</td>\n",
       "      <td>nl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Frederik Dhondt']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13316</th>\n",
       "      <td>13316</td>\n",
       "      <td>De invloed van geluidspollutie op zeezoogdieren</td>\n",
       "      <td>[{'name': 'Department of Morphology (ceased 1-...</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Biology and Life Sciences']</td>\n",
       "      <td>['SONAR' 'BEAKED-WHALES']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://hdl.handle.net/1854/LU-4187126</td>\n",
       "      <td>https://biblio.ugent.be/publication/4187126/fi...</td>\n",
       "      <td>True</td>\n",
       "      <td>ugent_biblio</td>\n",
       "      <td>The ancestors of the current whale species (Ce...</td>\n",
       "      <td>nl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Marjan Doom', 'Pieter Cornillie', 'Ingrid Gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10879</th>\n",
       "      <td>10879</td>\n",
       "      <td>Nietigheid en ‘meest gunstige interpretatie’: ...</td>\n",
       "      <td>[{'name': 'Department of Interdisciplinary Stu...</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Law and Political Science']</td>\n",
       "      <td>['nulity' 'voidness' 'Caixabank' 'Kasler' 'Océ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://hdl.handle.net/1854/LU-8131260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>ugent_biblio</td>\n",
       "      <td>Onrechtmatige bedingen in overeenkomsten met c...</td>\n",
       "      <td>nl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Simon Geiregat']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3712</th>\n",
       "      <td>3712</td>\n",
       "      <td>Burn-out bij vroedvrouwen: een stille crisis i...</td>\n",
       "      <td>Arteveldehogeschool Gent</td>\n",
       "      <td>2025</td>\n",
       "      <td>['Helga Berghman', 'Isabel D’Hoker']</td>\n",
       "      <td>['Geneeskunde']</td>\n",
       "      <td>['vroedvrouw', 'burn-out', 'Re-integratie', 'l...</td>\n",
       "      <td>['Burn-out bij vroedvrouwen: een stille crisis...</td>\n",
       "      <td>https://scriptiebank.be/scriptie/2025/burn-out...</td>\n",
       "      <td>https://scriptiebank.be/file/22362/download?to...</td>\n",
       "      <td>True</td>\n",
       "      <td>scriptiebank</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Camille Hendrickx']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3817</th>\n",
       "      <td>3817</td>\n",
       "      <td>De KU Leuven: \"grensverleggend of conservatief?\"</td>\n",
       "      <td>KU Leuven</td>\n",
       "      <td>2025</td>\n",
       "      <td>['Joris Vandendriessche']</td>\n",
       "      <td>['Geschiedenis', 'Onderwijs']</td>\n",
       "      <td>['KU Leuven', 'internationalisering', 'Gender ...</td>\n",
       "      <td>['Tijdens het academiejaar 2024 – 2025 was één...</td>\n",
       "      <td>https://scriptiebank.be/scriptie/2025/een-grot...</td>\n",
       "      <td>https://scriptiebank.be/file/22173/download?to...</td>\n",
       "      <td>True</td>\n",
       "      <td>scriptiebank</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Alexe Heleu']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "6385    6385  Verslag: het métier en de opleiding van de Ned...   \n",
       "13316  13316    De invloed van geluidspollutie op zeezoogdieren   \n",
       "10879  10879  Nietigheid en ‘meest gunstige interpretatie’: ...   \n",
       "3712    3712  Burn-out bij vroedvrouwen: een stille crisis i...   \n",
       "3817    3817   De KU Leuven: \"grensverleggend of conservatief?\"   \n",
       "\n",
       "                                             affiliation  year  \\\n",
       "6385   [{'name': 'Department of Legal theory and lega...  2011   \n",
       "13316  [{'name': 'Department of Morphology (ceased 1-...  2013   \n",
       "10879  [{'name': 'Department of Interdisciplinary Stu...  2016   \n",
       "3712                            Arteveldehogeschool Gent  2025   \n",
       "3817                                           KU Leuven  2025   \n",
       "\n",
       "                                   promoter                         themes  \\\n",
       "6385                                    NaN    ['History and Archaeology']   \n",
       "13316                                   NaN  ['Biology and Life Sciences']   \n",
       "10879                                   NaN  ['Law and Political Science']   \n",
       "3712   ['Helga Berghman', 'Isabel D’Hoker']                ['Geneeskunde']   \n",
       "3817              ['Joris Vandendriessche']  ['Geschiedenis', 'Onderwijs']   \n",
       "\n",
       "                                                keywords  \\\n",
       "6385                      ['Historiography' 'Education']   \n",
       "13316                          ['SONAR' 'BEAKED-WHALES']   \n",
       "10879  ['nulity' 'voidness' 'Caixabank' 'Kasler' 'Océ...   \n",
       "3712   ['vroedvrouw', 'burn-out', 'Re-integratie', 'l...   \n",
       "3817   ['KU Leuven', 'internationalisering', 'Gender ...   \n",
       "\n",
       "                                           text_homepage  \\\n",
       "6385                                                 NaN   \n",
       "13316                                                NaN   \n",
       "10879                                                NaN   \n",
       "3712   ['Burn-out bij vroedvrouwen: een stille crisis...   \n",
       "3817   ['Tijdens het academiejaar 2024 – 2025 was één...   \n",
       "\n",
       "                                               page_link  \\\n",
       "6385               http://hdl.handle.net/1854/LU-1173782   \n",
       "13316              http://hdl.handle.net/1854/LU-4187126   \n",
       "10879              http://hdl.handle.net/1854/LU-8131260   \n",
       "3712   https://scriptiebank.be/scriptie/2025/burn-out...   \n",
       "3817   https://scriptiebank.be/scriptie/2025/een-grot...   \n",
       "\n",
       "                                           download_link downloaded  \\\n",
       "6385                                                 NaN      False   \n",
       "13316  https://biblio.ugent.be/publication/4187126/fi...       True   \n",
       "10879                                                NaN      False   \n",
       "3712   https://scriptiebank.be/file/22362/download?to...       True   \n",
       "3817   https://scriptiebank.be/file/22173/download?to...       True   \n",
       "\n",
       "             source                                           abstract  \\\n",
       "6385   ugent_biblio  Report on a conference featuring the position ...   \n",
       "13316  ugent_biblio  The ancestors of the current whale species (Ce...   \n",
       "10879  ugent_biblio  Onrechtmatige bedingen in overeenkomsten met c...   \n",
       "3712   scriptiebank                                                NaN   \n",
       "3817   scriptiebank                                                NaN   \n",
       "\n",
       "      language  pages  chapters  type  \\\n",
       "6385        nl    NaN       NaN   NaN   \n",
       "13316       nl    NaN       NaN   NaN   \n",
       "10879       nl    NaN       NaN   NaN   \n",
       "3712       NaN    NaN       NaN   NaN   \n",
       "3817       NaN    NaN       NaN   NaN   \n",
       "\n",
       "                                                 authors  \n",
       "6385                                 ['Frederik Dhondt']  \n",
       "13316  ['Marjan Doom', 'Pieter Cornillie', 'Ingrid Gi...  \n",
       "10879                                 ['Simon Geiregat']  \n",
       "3712                               ['Camille Hendrickx']  \n",
       "3817                                     ['Alexe Heleu']  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "df = pd.read_csv(Path('data/metadata.csv'))\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22cc1702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' parse new full documents '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' language -> language_abstract  + language_full '''\n",
    "# language_abstract\n",
    "from langdetect import detect, LangDetectException\n",
    "def detect_lang(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return None\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return None\n",
    "#df['language_abstract'] = df['abstract'].apply(lambda x: detect_lang(x[:150]) if isinstance(x, str) else None)\n",
    "df['language_abstract'] = df['abstract'].apply(detect_lang)\n",
    "''' select years from scriptiebank '''\n",
    "''' parse new full documents '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6060ffe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>year</th>\n",
       "      <th>promoter</th>\n",
       "      <th>themes</th>\n",
       "      <th>keywords</th>\n",
       "      <th>text_homepage</th>\n",
       "      <th>page_link</th>\n",
       "      <th>download_link</th>\n",
       "      <th>downloaded</th>\n",
       "      <th>source</th>\n",
       "      <th>abstract</th>\n",
       "      <th>language</th>\n",
       "      <th>pages</th>\n",
       "      <th>chapters</th>\n",
       "      <th>type</th>\n",
       "      <th>authors</th>\n",
       "      <th>language_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14053</th>\n",
       "      <td>14053</td>\n",
       "      <td>Na de goodwill, tijd voor actie : desinformati...</td>\n",
       "      <td>[{'name': 'Department of Communication studies...</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Social Sciences']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://hdl.handle.net/1854/LU-8731197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>ugent_biblio</td>\n",
       "      <td>Vaccintwijfel, politieke advertenties op Faceb...</td>\n",
       "      <td>nl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Kristin Van Damme', 'Annelore Deprez', 'Clio...</td>\n",
       "      <td>nl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5604</th>\n",
       "      <td>5604</td>\n",
       "      <td>Omarm de 15 minutenstad</td>\n",
       "      <td>[{'name': 'Department of Geography', 'path': a...</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Social Sciences' 'Earth and Environmental Sc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://hdl.handle.net/1854/LU-8739440</td>\n",
       "      <td>https://biblio.ugent.be/publication/8739440/fi...</td>\n",
       "      <td>True</td>\n",
       "      <td>ugent_biblio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Kobe Boussauw', 'Sarah De Boeck']</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>490</td>\n",
       "      <td>Vita voluptuaria: melancholie en architectuur</td>\n",
       "      <td>KU Leuven</td>\n",
       "      <td>2017</td>\n",
       "      <td>['Thierry Lagrange; Jo Van Den Berghe']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['literatuur']</td>\n",
       "      <td>['“Besides my other numerous circles of acquai...</td>\n",
       "      <td>https://scriptiebank.be/scriptie/2017/vita-vol...</td>\n",
       "      <td>https://scriptiebank.be/file/10114/download?to...</td>\n",
       "      <td>True</td>\n",
       "      <td>scriptiebank</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Bart Merlier']</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12753</th>\n",
       "      <td>12753</td>\n",
       "      <td>Onderzoek naar de impact van het capaciteitsta...</td>\n",
       "      <td>[{'name': 'Department of Electromechanical, Sy...</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Technology and Engineering']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://hdl.handle.net/1854/LU-8759452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>ugent_biblio</td>\n",
       "      <td>Deze studie behelst het onderzoek naar de impa...</td>\n",
       "      <td>nl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Robbert Claeys', 'Rémy Cleenwerck', 'Gianni ...</td>\n",
       "      <td>nl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8845</th>\n",
       "      <td>8845</td>\n",
       "      <td>'It takes a village to raise a child'</td>\n",
       "      <td>[{'name': 'Department of Comparative sciences ...</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Social Sciences']</td>\n",
       "      <td>['Brede School' 'doelen' 'visie' 'brede ontwik...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://hdl.handle.net/1854/LU-622777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>ugent_biblio</td>\n",
       "      <td>Brede School is een relatief nieuw begrip in h...</td>\n",
       "      <td>nl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Veerle Ernalsteen', 'Ella Desmedt', 'Ides Ni...</td>\n",
       "      <td>nl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "14053  14053  Na de goodwill, tijd voor actie : desinformati...   \n",
       "5604    5604                            Omarm de 15 minutenstad   \n",
       "490      490      Vita voluptuaria: melancholie en architectuur   \n",
       "12753  12753  Onderzoek naar de impact van het capaciteitsta...   \n",
       "8845    8845              'It takes a village to raise a child'   \n",
       "\n",
       "                                             affiliation  year  \\\n",
       "14053  [{'name': 'Department of Communication studies...  2021   \n",
       "5604   [{'name': 'Department of Geography', 'path': a...  2022   \n",
       "490                                            KU Leuven  2017   \n",
       "12753  [{'name': 'Department of Electromechanical, Sy...  2021   \n",
       "8845   [{'name': 'Department of Comparative sciences ...  2008   \n",
       "\n",
       "                                      promoter  \\\n",
       "14053                                      NaN   \n",
       "5604                                       NaN   \n",
       "490    ['Thierry Lagrange; Jo Van Den Berghe']   \n",
       "12753                                      NaN   \n",
       "8845                                       NaN   \n",
       "\n",
       "                                                  themes  \\\n",
       "14053                                ['Social Sciences']   \n",
       "5604   ['Social Sciences' 'Earth and Environmental Sc...   \n",
       "490                                                   []   \n",
       "12753                     ['Technology and Engineering']   \n",
       "8845                                 ['Social Sciences']   \n",
       "\n",
       "                                                keywords  \\\n",
       "14053                                                NaN   \n",
       "5604                                                 NaN   \n",
       "490                                       ['literatuur']   \n",
       "12753                                                NaN   \n",
       "8845   ['Brede School' 'doelen' 'visie' 'brede ontwik...   \n",
       "\n",
       "                                           text_homepage  \\\n",
       "14053                                                NaN   \n",
       "5604                                                 NaN   \n",
       "490    ['“Besides my other numerous circles of acquai...   \n",
       "12753                                                NaN   \n",
       "8845                                                 NaN   \n",
       "\n",
       "                                               page_link  \\\n",
       "14053              http://hdl.handle.net/1854/LU-8731197   \n",
       "5604               http://hdl.handle.net/1854/LU-8739440   \n",
       "490    https://scriptiebank.be/scriptie/2017/vita-vol...   \n",
       "12753              http://hdl.handle.net/1854/LU-8759452   \n",
       "8845                http://hdl.handle.net/1854/LU-622777   \n",
       "\n",
       "                                           download_link downloaded  \\\n",
       "14053                                                NaN      False   \n",
       "5604   https://biblio.ugent.be/publication/8739440/fi...       True   \n",
       "490    https://scriptiebank.be/file/10114/download?to...       True   \n",
       "12753                                                NaN      False   \n",
       "8845                                                 NaN      False   \n",
       "\n",
       "             source                                           abstract  \\\n",
       "14053  ugent_biblio  Vaccintwijfel, politieke advertenties op Faceb...   \n",
       "5604   ugent_biblio                                                NaN   \n",
       "490    scriptiebank                                                NaN   \n",
       "12753  ugent_biblio  Deze studie behelst het onderzoek naar de impa...   \n",
       "8845   ugent_biblio  Brede School is een relatief nieuw begrip in h...   \n",
       "\n",
       "      language  pages  chapters  type  \\\n",
       "14053       nl    NaN       NaN   NaN   \n",
       "5604        nl    NaN       NaN   NaN   \n",
       "490        NaN    NaN       NaN   NaN   \n",
       "12753       nl    NaN       NaN   NaN   \n",
       "8845        nl    NaN       NaN   NaN   \n",
       "\n",
       "                                                 authors language_abstract  \n",
       "14053  ['Kristin Van Damme', 'Annelore Deprez', 'Clio...                nl  \n",
       "5604                 ['Kobe Boussauw', 'Sarah De Boeck']              None  \n",
       "490                                     ['Bart Merlier']              None  \n",
       "12753  ['Robbert Claeys', 'Rémy Cleenwerck', 'Gianni ...                nl  \n",
       "8845   ['Veerle Ernalsteen', 'Ella Desmedt', 'Ides Ni...                nl  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a210f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(Path('data/metadata.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f64d837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language_abstract\n",
       "nl    3954\n",
       "en    1450\n",
       "af      28\n",
       "fr      20\n",
       "de      10\n",
       "ro       7\n",
       "ca       2\n",
       "sl       1\n",
       "it       1\n",
       "id       1\n",
       "et       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language_abstract.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce9d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' easier for reusing code '''\n",
    "\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "class DatasetLoader:\n",
    "    def __init__(\n",
    "            self,\n",
    "            csv_path=Path('data/metadata.csv'),\n",
    "            zip_path_papers=Path('data/archive.zip'),\n",
    "            zip_path_marker = Path('data/output_marker.zip')\n",
    "            ):\n",
    "        \"\"\"\n",
    "        :param csv_path: Path to the metadata CSV\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.zip_path_papers = zip_path_papers\n",
    "        self.zip_path_marker = zip_path_marker\n",
    "        \n",
    "        print(f\"Loading Metadata from {csv_path}...\")\n",
    "        self.df = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # We will store a set of all filenames found inside the ZIPs here\n",
    "        # Using a set makes lookups O(1) (instant)\n",
    "        self.zip_file_index = set()\n",
    "        self.zip_map = {} # Maps filename -> which zip file it belongs to\n",
    "        self._index_zip_files()\n",
    "\n",
    "    def _index_zip_files(self):\n",
    "        \"\"\"Internal method to scan ZIPs and store filenames in memory.\"\"\"\n",
    "        print(\"Indexing ZIP contents (this might take a moment)...\")\n",
    "        total_files = 0\n",
    "        \n",
    "        for z_path in self.zip_paths:\n",
    "            try:\n",
    "                with zipfile.ZipFile(z_path, 'r') as zf:\n",
    "                    # Get list of files without extracting\n",
    "                    files = zf.namelist()\n",
    "                    # Filter out directories (usually end in /)\n",
    "                    files = [f for f in files if not f.endswith('/')]\n",
    "                    \n",
    "                    for f in files:\n",
    "                        self.zip_file_index.add(f)\n",
    "                        self.zip_map[f] = z_path\n",
    "                        \n",
    "                    total_files += len(files)\n",
    "                    print(f\"  - Found {len(files)} files in {os.path.basename(z_path)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {z_path}: {e}\")\n",
    "\n",
    "        print(f\"Indexing complete. Total files in ZIPs: {total_files}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "    def get_counts(self):\n",
    "        \"\"\"Returns a quick summary of the dataset.\"\"\"\n",
    "        print(f\"Metadata Rows: {len(self.df)}\")\n",
    "        print(f\"Zip Files stored: {len(self.zip_file_index)}\")\n",
    "        return {\n",
    "            \"csv_rows\": len(self.df),\n",
    "            \"zip_files\": len(self.zip_file_index)\n",
    "        }\n",
    "\n",
    "    def check_integrity(self, id_column, extension=None):\n",
    "        \"\"\"\n",
    "        Checks if IDs in CSV exist in the ZIP files.\n",
    "        :param id_column: The column in CSV containing filenames/IDs\n",
    "        :param extension: (Optional) If CSV has '123' but ZIP has '123.txt', pass '.txt'\n",
    "        \"\"\"\n",
    "        # 1. Prepare CSV IDs\n",
    "        csv_ids = self.df[id_column].dropna().astype(str).unique()\n",
    "        \n",
    "        if extension:\n",
    "            # Add extension if missing\n",
    "            csv_ids = [f\"{x}{extension}\" if not x.endswith(extension) else x for x in csv_ids]\n",
    "        \n",
    "        csv_set = set(csv_ids)\n",
    "        \n",
    "        # 2. Perform Set Operations\n",
    "        # Present in CSV but missing from ZIP\n",
    "        missing_in_zip = csv_set - self.zip_file_index\n",
    "        # Present in ZIP but not in CSV\n",
    "        extra_in_zip = self.zip_file_index - csv_set\n",
    "        \n",
    "        print(f\"Integrity Report for column '{id_column}':\")\n",
    "        print(f\"  - Matches found: {len(csv_set.intersection(self.zip_file_index))}\")\n",
    "        print(f\"  - Missing from ZIPs: {len(missing_in_zip)}\")\n",
    "        print(f\"  - Extra files in ZIPs: {len(extra_in_zip)}\")\n",
    "        \n",
    "        if len(missing_in_zip) > 0:\n",
    "            print(f\"  - Sample missing: {list(missing_in_zip)[:3]}\")\n",
    "\n",
    "        return list(missing_in_zip)\n",
    "\n",
    "    def read_file_content(self, filename):\n",
    "        \"\"\"Reads the content of a specific file from the correct ZIP.\"\"\"\n",
    "        if filename not in self.zip_file_index:\n",
    "            print(f\"Error: {filename} not found in any ZIP.\")\n",
    "            return None\n",
    "            \n",
    "        target_zip = self.zip_map[filename]\n",
    "        \n",
    "        with zipfile.ZipFile(target_zip, 'r') as zf:\n",
    "            with zf.open(filename) as f:\n",
    "                # Assuming text files, decode bytes to string\n",
    "                return f.read().decode('utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marker_full",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
